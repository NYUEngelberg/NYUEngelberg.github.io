---
title: glams
##keywords:
##summary: "c'mon GLAMs"
sidebar: glams_sidebar
permalink: glams.html
folder: GLAMS
---

<!----- Conversion time: 77.486 seconds.


Using this Markdown file:

1. Cut and paste this output into your source file.
2. See the notes and action items below regarding this conversion run.
3. Check the rendered output (headings, lists, code blocks, tables) for proper
   formatting and use a linkchecker before you publish this page.

Conversion notes:

* Docs to Markdown version 1.0β22
* Fri Apr 24 2020 04:36:27 GMT-0700 (PDT)
* Source doc: Lock Text Conversion Test Version
* Tables are currently converted to HTML tables.
* This document has images: check for >>>>>  gd2md-html alert:  inline image link in generated source and store images to your server.
----->


# [1.  Introduction](#1_introduction)

_Today is a big day for Amina, age 11. She has already analyzed the cracks in 5th-century sculptures of the Buddha to learn about climate change in central Asia. She has also compared 3D printed dinosaur and bird pelvises to track evolution. Once she even became an ancient Greek sculptor by digitally remixing kouroi to create her very own. Her favorite video game—set in a series of Renaissance cathedrals—is built around puzzles made up of column capitals, gargoyles, and church portals._

_In fact, she has interacted with hundreds of different objects from museum collections all over the world. But today is different. Today she is going to the City Museum to see the original objects for herself, in person._

Amina’s story is the result of two powerful trends shaping the Galleries, Libraries, Archives, and Museums (GLAM) community. The first is digital content creation: the process of freeing pieces of a collection from the limits of their physical materiality and enabling them to exist in a virtual space. The second is Open Access: making those digital objects available for everyone to use without restriction.



## [1.1 What This Paper Will Help You Achieve](#1.1_what_this_paper_will_help_you_achieve)

This resource is designed to help you implement an Open Access program for the 3D digitization of cultural resources (e.g., human- and natural-made objects; events; and environments). In most cases, it assumes “you” are working at a GLAM institution and are interested in implementing a 3D Open Access program there. It provides you with the tools to identify technical and legal characteristics of cultural resources that will lend themselves to digitization. The paper describes the steps required to actually create these resources, helping you approach the digital content creation process with confidence. Finally, this paper will explain how you can launch a successful Open Access program, allowing the public to engage with digitized versions of the works in your collection at a broad scale.

Open Access is critical to this process. Digital and digitized assets do not merely serve as archives and records: they exist as [digital objects](https://www2.archivists.org/glossary/terms/d/digital-object) in and of themselves, as well as in relationship with hardware and software environments that present and represent them to us. The greater aim is to make use of cultural resources in contemporary life for accessible,[^1] creative, commercial, and learning purposes with a vital agency. Digital cultural resources should enable and empower a broad spectrum of users, now and in the future, to fashion new cultural production without undue burden or restrictions. Open Access is a baseline requirement when creating born digital and digitized content in the 21st century.

Starting your digital content creation process with Open Access approaches and methods will help in decision-making and taking actionable steps as you advance your creation, production, and distribution efforts. As such, openness, in its most equitable, expansive, and optimistic sense, is a guiding ethos and ethical principle when undertaking this work. Open Access may be new to you, but that does not make it an impossible goal. Others have come before you, paved the way, and demonstrated best practices. The approaches and examples in this paper will inform and inspire you on your Open Access journey.



## [1.2   How This Paper Is Structured](#1.2_how_this_paper_is_structured)

This paper is designed to be both an introduction and reference to your digital 3D content creation process. An initial reading will give you a grounding in how to begin to approach your Open Access program. As you start to implement the program, this paper can serve as a reference to return to in order to understand specific points that suddenly become relevant.

Once you move beyond this introduction, this paper begins by providing you context around Open Access. That section explains what Open Access is and how using an Open Access approach can help you structure your successful digital content program. It will also help you appreciate why Open Access is critical to a successful digital content process.

From there the paper moves into important technical background about digital 3D models. Understanding—or at least being familiar with—the technical characteristics of 3D models will help you understand what kinds of objects lend themselves most readily to the types of digitization described in this resource. It will also help you start to appreciate the various options for how to technically approach the digital content process, as well as identify specific use cases and audiences for the 3D models.

At that point, the paper begins to focus on the process itself. These sections will help you structure your approach so that it is a success. That includes understanding use cases and audiences for 3D models; the creation, storage, and preservation of the 3D models themselves; and making those 3D models available to the public.

The technology and practices related to Open Access 3D digital content creation and its release under Open Access principles are rapidly evolving. We hope to regularly update this paper and website in order to give you confidence that the information you are receiving is as relevant and timely as possible.


##    [1.3. How to Approach Your Open Access Program](#1.3_how_to_approach_your_open_access_program)

Your Open Access program involves a number of steps. Each of the steps summarized below is explored more fully in its corresponding section.[^2]



###        [1.3.1. Set Goals](#1.3.1_set_goals)

Identify the key objectives, routes to, and measure of success for your 3D digital content creation and publishing project. This includes identifying potential users and those users’ needs. Creating and distributing 3D digital content involves a number of choices and tradeoffs. Having concrete goals will help you evaluate your options and make decisions to match your intended outcomes. When setting goals, be sure to keep in mind the distinction between project outputs (e.g., “X number of 3D models published online”) and outcomes (e.g., “Increased engagement with our organization’s online collection records”).



###        [1.3.2. Identify](#1.3.2_identify)

Select cultural resources for digital content creation that align with your project goals and assess their suitability for digital 3D creation methods based on technical, legal, and ethical grounds.



###        [1.3.3. Digitize](#1.3.3_digitize)

Create digital content of the cultural resource in 3D through born digital or digitization methods, record metadata, paradata, structured data, and document the process openly.[^3]



###        [1.3.4. Disseminate](#1.3.4_disseminate)

Deliver the output 3D files to your identified audience in the best way possible. This includes making the files viewable to users and making various versions of the files available to users, as well as associated para and metadata about the object, the files, and provenance for both.  \




###        [1.3.5. Evaluate](#1.3.5_evaluate)

Having established goals and implemented the Open Access program, it is time to reflect upon what worked, what did not, and what is left to do. Whenever possible, this evaluation should be shared publicly and with open licenses to the wider Open GLAM sector so that others can learn from your successes.



# [2. What Is Open Access?](#2_what_is_open_access)

Open Access involves releasing works under a permissive license.[^4] Open Access content and cultural resources are free of most copyright and licensing restrictions and are often available to a user without a fee. For the underlying cultural resource or its digital content to be Open Access, the copyright holder grants everyone the ability to copy, use, and build upon the work without restriction, or it is in the worldwide public domain.[^5]

Open Access encompasses a holistic and interdependent set of legal, philosophical, policy, and production conditions for an organization.

Even if members of an organization are unable to make objects themselves available under an Open Access policy, due to copyright status or other restrictions, they can still include annotations, along with identifying and descriptive metadata as part of the Open Access release. As platforms for the display and download of 3D cultural resources grow and evolve, it will become increasingly important for cultural institutions to develop policies governing the entry, publishing, and export of metadata. A useful piece of metadata that could help as 3D model cultural resources proliferate in copies and derivatives is a Globally Unique Identifier (GUID) for the object. Institutions can then link various collections of data together with Digital Object Identifiers (DOI), mapping those DOIs to the object’s GUID.[^6] Interoperable and portable metadata are most helpful across systems and use cases.

The key is to consider Open Access at the outset, including how the Open Access policy will apply to the object and any metadata associated with the object. Many more organizations can participate in building a global [cultural commons](https://wiki.p2pfoundation.net/Cultural_Commons) today by updating existing contracts and work-for-hire agreements (in jurisdictions where such agreements are appropriate) for creators to make content open from the outset, rather than having to wait decades for the works to enter the public domain or try to renegotiate the terms long after initial production. Institutions often have a limited perspective on Open Access, viewing it as relevant only to cultural works from the historical past. Open Access can also apply to assets in contemporary production. This is achieved by implementing more permissive contract and licensing procedures for new works of creative production with contemporary cultural resources.

The speed of digital content creation is fast and accelerating, and your organization’s agreements, policies, and digital infrastructure need to keep up. Open Access can help your organization be agile and future-ready with content made, stored, and deployed through multiple platforms and systems.



##    [2.1. What Are You Providing Access To?](#2.1_what_are_you_providing_access_to)

Your Open Access program provides access to various cultural resources. The nature of those resources depends on the defining characteristics, contexts, locations, and situations of your organization. Three categories of cultural resources, as conceived of and defined by the authors, are:



###       [2.1.1. Events](#2.1.1_events)

An event is an activated occurrence accomplished by humans, nature, or generative artificial intelligence. While these events happen in a specific time and place, they can be documented in a wide variety of ways, from written accounts, to photographs, to conceptual frameworks (e.g., CIDOC-CRM), to 3D digital content.



###       [2.1.2. Environments](#2.1.2_environments)        

An environment is a place, setting, site, or structure made and affected by human, natural, or computationally generative activity.



###       [2.1.3 Objects](#2.1.3_objects)        

An object is an intangible, such as a dance performed at a specific time and place, or tangible, such as a manuscript, manifestation with cohesive properties that may be animate or inanimate, made by humans, generative artificial intelligence, or nature. Objects exist in many forms and types. Documents, which are records that take a form in media, are included within the context of objects for this paper.



##    [2.2. Consider Notions of Heritage with Cultural Resources](#2.2_consider_notions_of_heritage_with_cultural_resources)

When preparing to implement digital content production and Open Access programs, it is important to consider notions of heritage with respect to cultural resources. Heritage is a concept that for some may elicit celebration or pride and reflect on a sense of tradition, while for others, heritage is linked to problematic practices such as entitled inheritance, hypernationalism, patrimony, and provincialism.

What could an accessible and inclusive notion of heritage look like? Consider how cultural resources might be broadly utilized as a means to inspire and enable many people, regardless of origin, affinity, ability, or difference. Examine how cultural resources could help people to see themselves and the rest of the world from new points of view beyond their own affiliations and ancestors to empathetically engage others. Explore how cosmopolitan and nuanced understandings of cultural resources can foster connections among people, cultures, and the world at large, rather than being valued in and of themselves or as the sole province of one person or group.[^7] Consider why some cultural resources lend themselves to Open Access more than others, in consultation with relevant stakeholders and communities.

Discerning ethical positions on heritage and cultural resources is a consultative process that includes staff, communities, and stakeholders. Sharing the outcome of that process publicly is an important task to complete prior to digital content creation. This is especially true in the Open Access context, where digitized cultural works may be re-used downstream by other content creators and users acting independently from your organization, its contexts, and its relationships with stakeholders.



##    [2.3. Open Access Drives An Organization’s Mission and Empowers Its Vision](#2.3_open_access_drives_an_organizations_mission_and_empowers_its_vision)

Open Access is one of the most important priorities of any 21st-century cultural organization. Many institutions have priorities for public engagement and service as core elements of their missions. This commitment to service extends to both commercial and non-commercial entities related to an organization, including individuals, academics, and corporations, as well as nongovernmental and community organizations.

Open Access leverages the collaborative, distributed, innovative, and scalable possibilities of sharing data and media assets on the internet to empower an organization’s own vision. It also fuels the creative visions of makers across the globe to create, remix, and make new expressions in the form of products and services. William Griswold, director and president of The Cleveland Museum of Art, in speaking about the museum’s mission and its commitment to Open Access, stated:


>If our goal is to make the museum’s great comprehensive collections—of art from every period and from every corner of the globe—universally accessible and free of charge to audiences of all ages, regardless of where they live; if our objective is to facilitate the dissemination of new knowledge; if we are committed to transparency, to fostering creativity, to engaging communities within and far beyond our region, then there is almost nothing we can do that would have greater impact. With this move to Open Access, we have transformed not only access to the CMA’s collection but also its usability inside and outside the walls of our museum. Whenever, wherever, and however the public wishes to use, re-use, remix, or reinvent the objects that we hold, our collection is available—as it should be—for we are but caretakers of these objects, which belong to the artistic legacy of humankind.[^8]



To put it directly and simply, Open Access is mission and vision critical for any cultural organization and their partners today.



##    [2.4. What Does Open Access Achieve For A Cultural Organization?](#2.4_what_does_open_access_achieve_for_a_cultural_organization)[^9]

###   [2.4.1. Increased Engagement with Cultural Resources](#2.4.1_increased_engagement_with_cultural_resources)

Open Access increases engagement with cultural resources by closing the gap between discovery and re-use of resources by users, allowing users to sidestep burdensome, unnecessarily costly, and inefficient rights and permissions processes in order to engage with a cultural resource they discover. Open Access cultural resources propagate across sites and into communities, significantly increasing the likelihood that a member of the public will come into contact with them in the near term after launch, on an institution’s own hosted platform, or with the long-tail in partnership with organizations such as Creative Commons,[^10] Internet Archive, and Wikimedia.

For example, Wikimedia users have viewed works from The Metropolitan Museum of Art’s Open Access collection over 565 million times since 2017.[^11] The Cleveland Museum of Art’s Open Access collection had over 8 million views in its first year alone.[^12] Works from the Rijksmuseum Open Access collection—an early leader—have been viewed almost 2 billion times.[^13] The numbers demonstrate availability and reach through partnership on platforms focused on dedicated user communities with popular appeal and wider awareness.



###        [2.4.2. Cost Savings and Reprioritization](#2.4.2_cost_savings_and_reprioritization)

A key incentive for cultural organizations to do Open Access is cost savings and reprioritization of staff time, labor, and tools. The cost of operating a rights and permissions program often exceeds associated revenue because of staff salaries, benefits, and inefficiencies in the process of administering policies and fulfilling requests.[^14] Licensing simply does not generate net revenue for most cultural resource stewards and creators, including cultural organizations.

While an Open Access program will require new upfront investments, those investments will result in long-term benefits.

Staff tasks and roles formerly dedicated to rights and permissions processes can be reassigned to more productive and useful tasks that add value to the content and context of cultural resources. This can include improving data, such as creating additional metadata, alt tags and text, verbal descriptions, and translations. Institutions can also devote resources to including bibliographic and citation data in databases associated with cultural resource items to augment knowledge about the items through publications. Improving the informational quality of cultural resources gives them greater potential and more agency when utilized by a broad spectrum of content creators.



###        [2.4.3. New Creative and Economic Opportunities](#2.4.3_new_creative_and_economic_opportunities)

Open Access can provide new creative and economic opportunities for organizations or independent content creators. Many cultural institutions also have businesses within them, such as brand, licensing, and trademark, as well as merchandising and retail. Cultural institutions operating businesses in an Open Access context need to think differently, take new approaches, and abandon highly controlling licensing agreements with limited terms.[^15] An Open Access marketplace is more competitive and free as makers have to inspire engagement and purchases through the quality of their product without the shield of restricted licensing frameworks. Innovative applications of digital content products, empowered by Open Access, can accelerate potential profits in the digital economy, especially in partnership with organizations and influencers that magnify the customer engagement with your brands.

Notable examples of new product innovation include the Rijksmuseum [Rijksstudio Awards](https://www.rijksmuseum.nl/en/rijksstudioaward) and National Gallery of Denmark (Statens Museum for Kunst) [Art Jewels](https://www.shapeways.com/blog/archives/35612-melancholy-minimalism-smk-jewelry-contest-winner-3different.html) contest with Shapeways. Both initiatives leveraged Open Access programs to increase interactions with the collections and drive revenue. These fall within the realm of seeking to update the traditional museum merchandise and retail offering with items for sale in the physical and online stores.

More accessible marketplaces are available on platforms like Sketchfab, MyMiniFactory, Thingiverse, and Adobe Stock 3D, where 3D models and prints can be purchased. Prints in this case frequently carry on the traditional cultural resource role of sculpture, while models in digital form can be used in other formats, such as mixed reality experiences,[^16] augmented reality mobile applications, and video games. Organizations should seek to collaborate with these new sellers for brand and marketing partnerships, and to deliver their 3D models to more audiences than could be achieved alone to align with user communities and incentivize new growth. The technological reproducibility and remixing of culture has increased at global scale, demonstrating that positions of control and ownership of information assets like 3D models are misaligned if not mythical at this point.[^17]

Some may see new platforms as undermining revenue generation. However, changes in economics and technology have revealed that we are in a post-scarcity[^18] economy, especially in the context of information products like data and media assets such as 3D models of cultural resources. These assets can be effectively distributed and provided at low cost, nearly ad infinitum if it were not for copyright and other restrictions placed on them. This suggests that a restrictive licensing-based approach to the access and use of content is no longer effective at scaling and sustaining revenue for cultural institutions, which cannot compete at the same level as major multinational brands or entrepreneurial individuals whose earned revenue fuels present growth and invests in the future. In today’s networked world, collaboration with a wide range of communities provides more value to institutions than controlling resources.

There is simply too much competition for potential customers’ time and money in today’s economy for institutions to rely on resource control for success, especially with foundational and building-block resources like 3D models. An organization or creator needs to be working diligently on pursuing new business models with a prudent yet urgent approach to risk-taking. Waiting out the clock on traditional licensing does greater damage to an organization by leaving it further behind in a dynamic and fast-paced marketplace that has embraced remixes and fan-created content to keep a brand relevant and relatable to audiences. Cultural organizations might look to the leadership in the 3D space from the retail sector, whose competitive and market-driven needs urge new technological adoption to meet the desires of customers.[^19]

Digital production tools for cultural resource makers are becoming more accessible and user friendly in terms of platform, process, and price. The rise of 3D will occur alongside further innovations in technology that will make 3D models easier to access and use. In the case of 3D models, cultural organizations need to advance and scale up their 3D digitization programs and licensing frameworks to meet this new landscape and user experience demand. Otherwise, cultural organizations will find themselves in the same place they were with 2D images, with user-generated content having more significant adoption because of its sheer availability and usability. Organizations and their leadership must make critical decisions about how to ramp up 3D model production, with respect to financial and staff resources, whether this is addressed by government, philanthropy, or earned revenue. Institutions themselves are empowered and responsible for taking decisive and earnest action to enhance its capabilities and output for a digitization program. Blaming a lack of investment in digital engagement on external factors is not an appropriate way for an organization to excuse a lack of preparedness or mismanagement. Institutions need to sincerely respond to new cultural and market demands. These decisions are about making prudent choices and priorities. Opportunities are ahead for those with the tenacity to chart new courses creatively and economically for cultural resources.



###        [2.4.4. Potential for Greater Authenticity Through Ubiquity](#2.4.4_potential_for_greater_authenticity_through_ubiquity)

Open Access cultural resources may have the potential for greater authenticity than closed cultural resources through the amplification of ideas and sources, along with critical interrogation.

Authenticity should be understood primarily through its expressive qualities, rather than nominal properties. Notions regarding a cultural resource’s status as “original” or “copy” do not apply. Identified authorship[^20] has important legal considerations in some jurisdictions, community importance for others, and is useful information; however, it does not have bearing on the expressive authenticity value of a cultural resource. Expressive authenticity[^21] is experienced in a cultural resource through its essential communicative agency.[^22] It is informed by, but not limited to, one cultural context, origin, or mode of interpretation. Expressive authenticity could also be considered as expressive life, in dimensions of “being and behavior”[^23] and “composed of elements—relationships, memory, aspiration, belief.”[^24] The expressive authenticity of cultural resources requires us to seek their “significant properties” or those “core attributes...that should resist change over time even as performance environments change” within “blurry” and “boundless” aspects of their performative natures as variable media.[^25] Cultural resources are thus plastic instruments, able to be utilized by any number of potential users, who apply their intent and take action in multiple and yet undetermined environments or scenarios.

Open Access content can increase the quality and number of citations, links, views, and usages across a global ecosystem of platforms. Institutions have addressed authenticity of 2D images of cultural resources by making their high-quality produced images and metadata available as Open Access to address what is colloquially referred to as the “Yellow Milkmaid Syndrome.”[^26] This visibility can raise awareness to inform and inspire cultural interpretation and production. Open Access can empower users of the cultural resource content to make new resources and share information at scale and across borders. Open Access too may help humans, and generative artificial intelligence, in pursuing a more inclusive and nuanced truth that expands our capacities to understand through multiple vantage points, manifestations, and sources. The cultural, ecological, economic, and humanistic values of a cultural resource could flourish with its ubiquity via the internet and connected digital tools. Prudently, this potential greater authenticity through ubiquity should be coupled with a process of discernment with respect to use.

Cultural resources, especially those in the worldwide public domain, are the foundations of Open Access and speak to the truth of a shared commons of creation and use. Cultural resources are a wellspring that continually inspire and give life to new forms of creation. Their essences carry on throughout time by being passed between and through humanity and nature and by being incorporated and re-incorporated. As such, cultural resources are not wholly lost or diminished. They may migrate, mix, and recombine to form new entities. 3D models of cultural resources can make new connections and interactive creative manifestations possible for so many around the world through events, environments, and objects with their immersive presences.[^27] 3D models will define new dimensions and build immersive synergistic spaces for cultural resources.



# [3. What is a 3D Model?](#3_what_is_a_3D_model)
##    [3.1. Introduction to 3D Models](#3.1_introduction_to_3d_models)

In the simplest terms, a 3D model is just another kind of image: a way to show something to another person who is geographically or temporally removed from the original, physical cultural resource.

When compared with other media—images or video, for example—3D models are unique in one regard: their interactivity. A 3D model that you can interact with on a viewing device by rotating, zooming, and translating is said to be real-time 3D, as opposed to an image or a video of a 3D model, which is said to be pre-rendered. 3D models can also become physical 3D objects that can be touched, held, and examined without harming the originals.

3D models can have advantages over 2D images. A single image will show one view of a resource, cropped and zoomed a single way. An orthographic set will show more views (front, back, left, right, top, bottom) again at single crop and zoom levels. In contrast, a 3D model can be viewed from an infinite number of angles, a similar amount or zoom levels, and infinite cropped views. This is not to say that 3D is a superior approach to imaging in every context, but it does afford viewers new ways to look at a given resource.

Some common use cases for 3D models include:

*   Interactive display—e.g., on a screen, touchscreen, projection, hologram, or head-mounted display
*   Analysis and measurement—e.g., distance, volume
*   Creating physical replicas
*   Documenting physical changes in a cultural resource over time

3D models themselves should not be confused with the experiences that are built using them. Virtual and augmented reality, digital interactive games, animations, or film use 3D models much the same way that 2D images are involved in the production of a book, by drawing on a library of discrete files to build something bigger.[^28]

Probably the most common type of 3D model is a surface model, a digital description of the outward contours and appearance of a physical shape or form. A surface model is built of faces, and, similarly to the pixel dimensions of a 2D image, the resolution of a 3D model can be described for the most part in terms of the number of faces (the facecount) used to represent a cultural resource. Surface models are a common output from photogrammetry, structured light, and x-ray CT workflows.


![Herakles wireframe head](images/herakles_full.png "Herakles wireframe head")


###### 3D surface model of Marble head of Herakles from The Metropolitan Museum of Art with the face edges (the wireframe) highlighted. This model was created using a photogrammetry workflow.

As the name suggests, this surface model has no concept or record of a cultural resource’s internal structure—it is akin to a papier-mâché model in the real world: empty on the inside. By way of example, a 3D surface model of a wooden statue holds no record of the wood’s internal grain.



![Herakles wireframe head bisected](images/herakles_half.png "Herakles wireframe head bisected")


###### The same 3D surface model of Marble head of Herakles bisected, showing that it is hollow inside. The inward faces have been colored blue and a light and shadow added for easier recognition of this feature.

Another common type of 3D model is the point cloud. Instead of representing a physical shape with faces, we can also describe it using a number points or dots arranged in 3D space.



![Herakles Pointcloud](images/herakles_pointcloud.png "Herakles Pointcloud")


###### The same cultural resource represented by 3D as a point cloud.


Both surface model and point cloud files can also include color data that is either captured as part of the 3D digitization process or authored as part of data post processing or during a 3D modeling workflow.

A more in-depth look at the anatomy of 3D files can be found in the “Anatomy of a 3D Model” section in the Appendix.



###        [3.1.1. Creating 3D Models](#3.1.1_creating_3d_models)

This section includes some general guidance regarding commonly used 3D creation techniques. A more in-depth analysis of each technique can be found in the Appendix section “Common 3D Capture and 3D Creation Techniques and Software.”

Broadly speaking, creating a 3D model of a cultural resource will entail either a 3D digitization or 3D modeling workflow. The former uses a chain of equipment and software to capture a cultural resource’s likeness in 3D; the latter typically involves a 3D artist or designer building a 3D reconstruction or illustration of the same.

The general goal of a digitization process is to capture a cultural resource as accurately as possible. 3D modeling can also illustrate that which does not exist anymore, exists only in a digital space, or is entirely hypothetical—a group of outputs collectively referred to as _born-digital content_.

While this paper would be remiss in not mentioning both digitization and modeling workflows, it should be noted that due to the generally more complicated rights involved in commissioning an artist to create a new 3D work, the advice given throughout this publication is most applicable to digitization projects.

By way of a simple example showing comparative outputs of digitization and 3D modeling workflows, consider the two representations of a Roman villa below as typical outputs of the two processes.



<p id="gdcalert4" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text3.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert5">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text3.png "image_tooltip")
An example of a 3D output from a digitization workflow: Photogrammetric model of [villa room by Cotswold Archaeology](https://sketchfab.com/models/880e8668f49d4dbdb367def61fb4c41a).



<p id="gdcalert5" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text4.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert6">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text4.png "image_tooltip")
A similar subject (an ancient Roman villa) as created via a 3D modeling workflow: Reconstruction—[Roman room in Londinium by Mieke Roth](https://sketchfab.com/models/627c75ee13334940ba42c51e87272714) for The British Museum.

Both methods of 3D production require a certain amount of practice to yield effective results (if you are undertaking the 3D production yourself), or commercial companies can be hired to do the work for you. The advice in this white paper is based on the assertion that building in-house capacity for 3D production is the better long-term strategy. Doing so will better enable the effective inclusion of 3D in every relevant aspect of your organization’s work, future proofing its capacity for media production. The proven maturity of audiences and use cases for 3D models makes setting up and staffing a 3D digitization program now as equally useful as investing in a 2D photography program.

Deciding which 3D creation technique to use will largely depend on the goals you have set, available budgets, staffing, and staff skills. Below is a quick summary of common options, starting with the most inexpensive and easy-to-use techniques.



1. Illustrative 3D Modeling
2. Photogrammetry
3. Structured Light Scanning
4. LiDAR/Laser Scanning
5. X-Ray Computed Tomography

3D modeling is the most inexpensive and accessible option for producing 3D models, due to [high-quality open source software options](https://www.blender.org) and a minimum of equipment requirements. However, 3D modeling is an artistic and technical discipline that requires significant training and experience to master—while you can set yourself up for 3D modeling quickly and easily, it is unlikely to yield especially useful results straight away. 3D modeling does, however, offer extensive opportunities to create 3D content based on existing 2D digital collections.[^29]

Photogrammetry, the technique of calculating a 3D model by taking pictures of a subject from lots of different angles, is the most available form of 3D digitization available today. You or your organization likely already possess the capture technology (a smartphone or dedicated photography equipment, such as a DSLR or compact camera). and with relatively little effort, [free software](https://github.com/alicevision/meshroom) can produce high-quality 3D outputs.

The current expense and training requirements push the remaining methods of 3D digitization listed beyond the reach of anyone wanting to experiment with 3D production before making a significant investment of time and money. This is especially true for smaller organizations with limited funding.

While the unique nature of an organization’s collections demands unique approaches to 3D digitization, some existing projects indicate broadly effective approaches to 3D digitization.

* [Malopolska’s Virtual Museums](https://sketchfab.com/blogs/community/digitizing-art-and-history-from-40-malopolska-museums/), Poland


    A project consisting of a regional digitization studio servicing some 40 museums, using a combination of photogrammetry and structured light digitization techniques. This project approaches 3D digitization with clearly defined digitization, publication, and interpretation stages, which is reflected in equally important digitization, post-production, and editorial staff roles.


* [Museum of British Colonialism](https://www.museumofbritishcolonialism.org/), UK/Kenya


    An entirely volunteer-led organization founded to creatively communicate a more truthful account of British colonialism. As an online first space, MBC uses digital tools, including 3D reconstructions based on archival photography and oral interviews, to “engage audiences in a more interactive way and present information that would otherwise be inaccessible.”[^30]


    [National Natural History Museum of Santiago](http://mnhn.gob.cl/sitio/), Chile


    Motivated by the results of an experimental photogrammetry-based digitization project, the museum has undertaken a large-scale program of 3D digitization for public display.[^31]


    In order to create highly detailed 3D models, including versions that accurately document the shape and colors of the original objects, every artifact is digitized twice by using structured light scanning and photogrammetry.


    [Scottish Maritime Museum](https://www.scottishmaritimemuseum.org/), Scotland


    This museum has defined two core audiences for their digitization work: in-house staff who monitor the condition of the objects in the museum’s care and more casual online viewers looking to discover the stories about the objects and learn about their past. This project’s standard workflow involves capturing accurate data via LiDAR scanner and combines this with photogrammetry data sets of the same cultural resource to patch any missing geometry data and add high-quality color data.[^32]


    [Konzerthaus Berlin](https://www.konzerthaus.de/en/), Germany


    An EU-funded project designed especially to reach younger, more socially disadvantaged people with little access to culture, focusing 3D outputs optimized for online and augmented reality viewing. This organization employed a commercial architecture firm to 3D model several venues and buildings, combining these 3D models with color data from extensive architectural photography.[^33]

There are many more approaches[^34] worth reading about as you plan your own 3D production project. Through such an investigation, it becomes clear (judged on their 3D output and audience reception) that hybrid approaches to 3D production are generally the most successful.

If we assume the most effective 3D outputs are those that both accurately document a cultural resource’s shape (geometry data) and appearance (color data), we likely require a workflow that involves calibrated spatial capture (structured light, LiDAR) with calibrated color capture (photogrammetry).

When possible, capturing the highest-resolution and most accurate 3D data will afford the broadest possible range of use cases for the original data set as well as derivative 3D assets based on it.

While this paper exists because the authors believe a considered approach to 3D digitization is the most prudent course of action, some readers may wish to jump right in and attempt a “minimum viable 3D digitization workflow.” If you simply wish to start exploring the process of capturing and publishing 3D models of cultural resources right now, the Quick Start 3D Digitization Guide in the Appendix is for you.



###     [3.1.2. 3D Digitization Data Output Categories](#3.1.2_3d_digitization_data_output_categories)

The production of a single 3D model can entail a large number and variety of digital files, all of which may be offered under Open Access for specific audiences. A broad overview of digital file categories follows.



####            [3.1.2.1. Input Data](#3.1.2.1_input_data)

Input data is the raw data captured at the initial digitization stage. For example, in a photogrammetry workflow, input data comprises digital images; in a laser scanning workflow, this would be the files output from the laser scanning hardware.



####            [3.1.2.2. Project Files](#3.1.2.2_project_files)

Most 3D production workflows entail some processing or cleaning of raw data inputs. Edited data will most likely be stored in a proprietary format designed to be opened by a single, specific piece of software.



####            [3.1.2.3. Archival 3D Data](#3.1.2.3_archival_3d_data)

Archival 3D data are the highest quality and fidelity output files from a given digitization scenario, intended to be accessible and readable in perpetuity. This data is likely of most use to expert audiences, including internal personnel responsible for collection management. Recommended archival 3D file formats for cultural heritage projects include X3D, U3D, PLY, DAE, OBJ, and STL.[^35]



####            [3.1.2.4. Derivative 3D Data](#3.1.2.4_derivative_3d_data)

Derivative 3D data are 3D models derived from the archival 3D data, most likely simplified in some way and converted to other 3D file formats to facilitate quick and easy access and re-use as part of an Open Access offering for wider audiences.



####            [3.1.2.5. Metadata and Paradata](#3.1.2.5_metadata_and_paradata)

For all of the previous types of data, it is useful to provide additional context to what the 3D data is (metadata) and how it was captured or created and processed (paradata).

Recording and exposing detailed technical information that describes how a cultural resource was captured or created in 3D allows relevant end users more opportunity to verify the value and practical uses for a given 3D data set.

A few 3D file formats allow for additional text data to be embedded within the file itself. However, the varied software and platform support for metadata embedded in a 3D file combined with the ease with which a 3D file can be edited make this a somewhat unreliable method.

A more common and robust way to save or supply metadata is as an external text file, web page or database entry that can be provided alongside a 3D model at the moment of end user interaction with the 3D data. Refer to Section 6.2 on Data Structures for further information.

If it is technically possible and practical to both embed metadata and paradata in a 3D file and provide links to permanent external records, this increases the chances of contextual information about a 3D model remaining linked to it as it is downloaded, re-used, and remixed.

For further guidance regarding what kinds of metadata and paradata to collect and how to do so, explore the work of Cultural Heritage Imaging and their [Digital Lab Notebook](http://culturalheritageimaging.org/Technologies/Digital_Lab_Notebook/), the [Europeana 3D Task Force Report](https://pro.europeana.eu/files/Europeana_Professional/Europeana_Network/Europeana_Network_Task_Forces/Final_reports/3D-TF-final%20report.pdf), and the [Smithsonian 3D Metadata Model](https://dpo.si.edu/blog/smithsonian-3d-metadata-model).



# [4. Set Goals](#4_set_goals)

As with most things, 3D digitization projects can benefit greatly from establishing a goal or set of goals from which can be derived a plan and strategy to achieve the desired result. End goals for a 3D digitization project can be very general (e.g., “We wish to experiment with new technology”) or very specific (e.g., “We need an accurate 3D model to facilitate production of a new gallery wall mount”). Either way, it is essential to establish agreed-upon goals that you, your colleagues, and service providers can reference during the planning, implementation, and execution of your digitization project. Furthermore, clearly defined goals make it much easier to verify the effectiveness of a project at its conclusion, paving the way for further activity, or curtailing that which is deemed ineffective.



##    [4.1. Target Audiences](#4.1_target_audiences)

Deciding on the intended audience for your 3D content will help dictate the 3D capture or creation methods you will use, the 3D outputs you will produce, and how your 3D data will be made available. Identifying audiences (e.g., “schoolteachers”) and needs (e.g., “to illustrate and 3D print in relation to history curriculum subject ‘The Romans’”) will help you define both the cultural resources to be captured or created in 3D, as well as the most beneficial resolutions, file formats, display platforms, and dissemination methods for the resulting 3D data.

Identifying a primary audience establishes the need for 3D production; identifying secondary and tertiary audiences (along with an accompanying strategy to reach them and facilitate serendipitous re-use) multiplies the value of the 3D data you are producing.[^36] Identifying these audiences does not foreclose serendipitous uses—they merely help in focusing your efforts.  While your audiences may vary, the following recommendations will help you think about the needs of various general audiences.



###       [4.1.1. Scholarly](#4.1.1_scholarly)

For in-depth investigations, the highest-fidelity 3D geometry and textures likely will be the most useful.[^37] It should be noted that achieving this grade of 3D data can require a greater financial investment in equipment and training, as well as staff and machine time required to compute 3D data and document workflows. At the same time, even lower-resolution files can still be useful in many scholarly contexts.

Regardless of the resolution of a given 3D model, it is crucial to offer extensive meta- and paradata alongside a 3D model offered for scholarly use. Meta- and paradata can help scholars contextualize low-resolution 3D models with errors by allowing them to understand how and under what conditions it was created. In this manner, even a well-documented low-resolution and error-filled 3D model can be of benefit to researchers.

Some examples of 3D data made available primarily for scholarly use can be found via the [Natural History Museum London’s Data Portal](https://data.nhm.ac.uk/dataset/3d-cetacean-scanning) and [MorphoSource by Duke University](https://www.morphosource.org/).



###        [4.1.2. Education](#4.1.2_education)

Instead of forming the core of scholarly analysis, educational uses of 3D models rely on the models to facilitate the learning of a related subject. They can be used to illustrate a type of jewelry feature or allow students to explore a species of insect. This application differs from what we describe as “scholarly” uses in that the 3D models are not necessarily the focus of the educational experience or research. Instead, the 3D model is used to facilitate learning about a related subject.

In conjunction with the expert knowledge associated with a cultural resource, 3D models are a perfect match for teaching about cultural heritage as part of an [object-based learning program](https://www.ucl.ac.uk/culture/schools/teaching-object-based-learning). \


Some examples of 3D models being used in the classroom are provided below:



*   [Replacing the Squeeze? Teaching Classical Epigraphy With 3D Models](https://sarahemilybond.com/2018/01/29/replacing-the-squeeze-teaching-classical-epigraphy-with-3d-models), Dr Sarah Bond, 2018
*   [Museum in a Box](https://museuminabox.org/make-your-own-pilot-feedback-from-two-auckland-primary-schools/)
*   [Merge VR Cube](https://mergeedu.com/cube)
*   [3D Objects for Teachers](https://www.sciencemuseum.org.uk/objects-and-stories/3d-objects-teachers), Science Museum Group, [write-up](https://lab.sciencemuseum.org.uk/3d-object-scans-as-a-museum-learning-resource-part-1-9e1e51b67581), [context](https://lab.sciencemuseum.org.uk/science-museum-group-digital-lab-introduction-and-projects-1f7a6f26a208)
*   [Samsung Discovery Centre @ British Museum](https://news.samsung.com/global/samsung-and-the-british-museum-offer-35000-school-pupils-the-chance-to-virtually-visit-the-museum)

###        [4.1.3. Public Engagement](#4.1.3_public_engagement)

3D models increasingly make up part of a “complete” digital offering for GLAM institutions seeking to engage members of the public with cultural heritage and history. Alongside text, audio, and images, 3D offers yet another way to examine and experience historical themes and narratives.

It is now easy to share and embed 3D on any website, blog, social media platform as part of outreach, education, marketing, and digital strategies. Examples of embedded 3D can be explored at the following institutions’ online collections:



*   [Minneapolis Institute of Art](https://collections.artsmia.org/search/_exists_:%22related:3dmodels%22)
*   [Cleveland Museum of Art](http://www.clevelandart.org/art/collection/search?i=1&only-highlights=1&only-open-access=1&only-in-3d=1)
*   [Museo Virtual de Morbase](https://montemorbase.com/museu-virtual/)
*   [Wirtualne Muzea Małopolska](http://muzea.malopolska.pl/en/?p_p_id=3&p_p_lifecycle=0&p_p_state=maximized&p_p_mode=view&_3_struts_action=%2Fsearch%2Fsearch&_3_groupId=0&_3_assetTagNames=3D+plus)
*   [British Museum, Portable Antiquities Scheme](https://finds.org.uk/database/search/results/q/%2A/3D/1)
*   [Smithsonian Institution](https://3d.si.edu/cc0)

Derivative 3D outputs like 3D prints and video are equally helpful for connecting general audiences with GLAM collections. The British Museum has incorporated 3D prints in their offering to primary schools during major exhibitions[^38] and video derived from 3D scans in their permanent galleries.[^39]



###        [4.1.4. Commercial](#4.1.4_commercial)

Whether in-house at a cultural organization or at an external private company, there are many opportunities for 3D models to become part of a commercial endeavor. There is nothing about making cultural objects available on an Open Access basis that is inherently incompatible with offering physical and digital versions for sale as well.

3D models can be used to create accurate physical replicas of cultural objects, which can be offered for sale in physical and online gift shops.[^40] Similarly, as long as the 3D data is generally available on Open Access terms, institutions can offer a license to use the institution’s name and brand to associate the use with the institution and officially verify its accuracy. Taken a step further, the institution may also make its experts available to consult with users on appropriate and accurate uses of the model.

Furthermore, all 3D data made available under an Open Access program remains available to the publishing organization to exploit in support of its own established commercial models. Offering rich, 3D-based on-site digital experiences such as those at the [Cleveland Museum of Art](https://sketchfab.com/blogs/community/photogrammetry-and-3d-model-viewer-advances-gesture-based-interactives/), [Swedish Historical Museums](https://sketchfab.com/blogs/community/api-spotlight-swedish-historical-museums/), and [Natural History Museum, London](https://sketchfab.com/blogs/community/nhm-london-building-custom-3d-interactives-sketchfab-api/) can attract visitors to physical venues where patrons may take advantage of paid exhibitions, gifts shops, and restaurants.



##    [4.2. Portion of Collection](#4.2_portion_of_collection)

To capture or render any given GLAM organization’s entire collection in 3D is most likely an impossible task. Producing a 3D model of each cultural resource in collections that can run into the thousands if not millions of subjects is simply impractical based on today’s technology.

However, if you wish to begin a 3D digitization program, you have to start somewhere. The easiest way to narrow down the scope of a 3D digitization project is to direct efforts at the part of the collection that relates to the needs of your primary audience. Depending on the identified audience need, a select portion of a collection can be further refined by digitizing only prime examples of a given type of cultural resource.

The defined number of cultural resources you wish to digitize should be achievable within the timeline and budget of your project. If you are undertaking a 3D production project for the first time, it may be prudent to limit the portion of a collection that you plan to digitize even further. This will give you greater leeway to account for unexpected delays or mistakes.



##    [4.3. Budget](#4.3_budget)

Your available budget has a direct impact on the quality of 3D models that you may produce. Consider the following expenses when planning your project:

Digitization and PostProduction

*   Equipment
*   Software
*   Training
*   Staffing (in-house, outsourced)
*   Digital storage and off-site backup
*   Preservation

Dissemination

*   Web servers
*   Service subscriptions
*   Promotion

##    [4.4. Partners](#4.4_partners)

Identify desired partnerships as part of the goal-setting process based on aspects of your project where you feel you need assistance or support. Partnerships can be valuable at all stages of a project: planning, digitization, post-production, and dissemination.

Partnerships can take many forms, such as collaboration with local universities and volunteers,[^41] online communities,[^42] or commercial companies.[^43]



# [5. Identify](#5_identify)

Identifying works to digitize involves considering a number of factors. Some are relatively straightforward: Are there characteristics of the object that make it technically hard to digitize? Are there intellectual property rights that would prevent digitization? What budgetary constraints must be taken into account?

Others will require more careful consideration and analysis: Are there cultural concerns that might make an object a poor fit for Open Access? Are works in danger of degradation or damage? Is there strategic, operational, or academic interest in prioritizing specific works in the collection?

This section will help you find answers to some of those questions.



##    [5.1. Which Works Are Good Technical Matches with 3D Scanning?](#5.1_which_works_are_good_technical_matches_with_3D_scanning)

Once a pool of cultural resources has been identified for digitization, the physical properties of those resources will largely dictate the method of digitization, or even disqualify them from digitization.

Generally speaking, digitization will be more complex (or indeed impossible) for objects that are highly reflective, too fragile to safely rotate in order to capture all sides in a scan, or feature extremely fine elements like hair or feathers.

Refer to the Appendix section “Common 3D Capture and 3D Creation Techniques and Software” for details on applications and limitations of different capture technologies. The following examples cover a range of hypothetical 3D digitization subjects and possible capture techniques dictated by the physical properties of the subject. In addition to digital capture technologies, a 3D artist could be used to create a 3D model of the object. It may also be assumed that for any of the following subjects, a 3D model could be created by a 3D artist who might use the physical cultural resource (and existing media thereof) as a reference.

A summary table is provided for quick reference, with more detailed notes beneath:


<table>
  <tr>
   <td>
   </td>
   <td>
   </td>
   <td colspan="5" >Potential Digitization Technique(s)
   </td>
  </tr>
  <tr>
   <td>Subject
   </td>
   <td>Digitization Complexity
   </td>
   <td>Photogrammetry
   </td>
   <td>Structured Light
   </td>
   <td>LiDAR
   </td>
   <td>X-Ray CT
   </td>
   <td>Motion Capture
   </td>
  </tr>
  <tr>
   <td>Insect Specimen
   </td>
   <td>4/5
   </td>
   <td> ✔*
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Coin
   </td>
   <td>3/5
   </td>
   <td>  ✔*
   </td>
   <td>✔
   </td>
   <td>
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Mammal Bone
   </td>
   <td>2/5
   </td>
   <td>✔
   </td>
   <td>✔
   </td>
   <td>
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Engraved Metal Platter
   </td>
   <td>3/5
   </td>
   <td> ✔*
   </td>
   <td>✔
   </td>
   <td>
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Glass Vase
   </td>
   <td>4/5
   </td>
   <td> ✔*
   </td>
   <td>✔
   </td>
   <td>
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Statue
   </td>
   <td>2/5
   </td>
   <td>✔
   </td>
   <td>  ✔*
   </td>
   <td>  ✔*
   </td>
   <td>  ✔*
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Building Interior & Exterior
   </td>
   <td>2/5
   </td>
   <td>✔
   </td>
   <td>
   </td>
   <td>✔
   </td>
   <td>
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Performance
   </td>
   <td>5/5
   </td>
   <td> ✔*
   </td>
   <td>  ✔*
   </td>
   <td>
   </td>
   <td>
   </td>
   <td>  ✔*
   </td>
  </tr>
</table>


  &#42; See notes for this subject type for specific workflow




###        [5.1.1. Insect Specimen](#5.1.1_insect_specimen)
**Significant Characteristics:**  
Very small (less than 1 inch), highly detailed, fine and thin features, internal and external features, complex self-occluding forms.

**Potential Digitization Technique(s):**

Photogrammetry “focus stacking” workflow, x-ray CT.

**Digitization Complexity:**

4/5.

**Examples:**





<div class="sketchfab-embed-wrapper">
    <iframe title="A 3D model" width="640" height="480" src="https://sketchfab.com/models/0cff43d6c8c14a058c3c8ed16e8bcb58/embed?preload=1&amp;ui_controls=1&amp;ui_infos=1&amp;ui_inspector=1&amp;ui_stop=1&amp;ui_watermark=1&amp;ui_watermark_link=1" frameborder="0" allow="autoplay; fullscreen; vr" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/3d-models/cryptocephalus-sericeus-0cff43d6c8c14a058c3c8ed16e8bcb58?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Cryptocephalus sericeus</a>
        by <a href="https://sketchfab.com/disc3d?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Digital Archive of Natural History (DiNArDa)</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
</div>

###### Technique: Photogrammetry + [Focus Stacking](https://en.wikipedia.org/wiki/Focus_stacking)



<p id="gdcalert7" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text6.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert8">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text6.png "image_tooltip")


[Pheidole lucida queen](https://sketchfab.com/models/c35bce7a8efb4bf5b852654b15931cf7) by [Economolab, JP](https://sketchfab.com/arilab)—x-ray CT scan to surface model.



###        [5.1.2. Coin](#5.1.2_coin)

**Significant Characteristics:**
Very small (less than 1 inch), highly detailed surface features, metallic, internal and external features.

**Potential Digitization Technique(s):**  
Photogrammetry with polarized light + focus stacking workflow, structured light scanning, x-ray CT.

**Digitization Complexity:**  
3/5.

**Examples:**

<div class="sketchfab-embed-wrapper">
    <iframe title="A 3D model" width="640" height="480" src="https://sketchfab.com/models/bb8dc376703c401586785b811fe28e15/embed?preload=1&amp;ui_controls=1&amp;ui_infos=1&amp;ui_inspector=1&amp;ui_stop=1&amp;ui_watermark=1&amp;ui_watermark_link=1" frameborder="0" allow="autoplay; fullscreen; vr" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/3d-models/aureus-de-marc-aurele-bb8dc376703c401586785b811fe28e15?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Aureus de Marc Aurèle</a>
        by <a href="https://sketchfab.com/museesaintraymond?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Musée Saint-Raymond</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
</div>

###### Technique: Photogrammetry



<p id="gdcalert9" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text8.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert10">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text8.png "image_tooltip")


[Silver Denarius | Silberdenar](https://sketchfab.com/models/34a498eb7df2491ba8a3ba5186df86f0) by [LAD BW, DE](https://sketchfab.com/ladbw)—structured light scanning.



###        [5.1.3. Mammal Bone](#5.1.3_mammal_bone)

**Significant Characteristics:**
Very small (less than 1 inch) to medium size (a few feet), internal and external features, complex self-occluding forms.

**Potential Digitization Technique(s):**

Photogrammetry, structured light Scanning, x-ray CT.

**Digitization Complexity:**

2/5.

**Examples:**

<div class="sketchfab-embed-wrapper">
    <iframe title="A 3D model" width="640" height="480" src="https://sketchfab.com/models/41d5fd1b83644f398de7cfc6304ef794/embed?preload=1&amp;ui_controls=0&amp;ui_infos=0&amp;ui_inspector=0&amp;ui_stop=0&amp;ui_watermark=1&amp;ui_watermark_link=1" frameborder="0" allow="autoplay; fullscreen; vr" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/3d-models/risch-rotkreuz-mammut-stosszahn-mammoth-tusk-41d5fd1b83644f398de7cfc6304ef794?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Risch-Rotkreuz, Mammut-Stosszahn / mammoth tusk</a>
        by <a href="https://sketchfab.com/ADA-ZG?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">ADA ZG</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
</div>

###### Technique: X-ray CT to surface model



<p id="gdcalert11" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text10.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert12">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text10.png "image_tooltip")


[Mary Rose carpenter’s skull](https://sketchfab.com/models/4b1ad3107de049f6af2c6d77f0113b56) by [MaryRose@SwanseaUniversity, UK](https://sketchfab.com/ncoa)—photogrammetry.



###        [5.1.4. Engraved Metal Platter](#5.1.4_engraved_metal_platter)
**Significant Characteristics:**

Metallic/shiny, fine surface detail, thin.

**Potential Digitization Technique(s):**
Photogrammetry with polarized light, structured light scanning, r-ray CT.

**Digitization Complexity:**

3/5.

**Examples:**



<p id="gdcalert12" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text11.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert13">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text11.png "image_tooltip")


[Copy of the Temperance Basin](https://sketchfab.com/models/a506e2a0307e4d589c9c6f8e74846d58) by [The V&A Museum, UK](https://sketchfab.com/vamuseum)—structured light scanning.



<div class="sketchfab-embed-wrapper">
    <iframe title="A 3D model" width="640" height="480" src="https://sketchfab.com/models/9d2c9b89148d4de6a173339b4a20a052/embed?preload=1&amp;ui_controls=1&amp;ui_infos=1&amp;ui_inspector=1&amp;ui_stop=1&amp;ui_watermark=1&amp;ui_watermark_link=1" frameborder="0" allow="autoplay; fullscreen; vr" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/3d-models/metal-platter-9d2c9b89148d4de6a173339b4a20a052?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Metal Platter</a>
        by <a href="https://sketchfab.com/santacruzmah?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Santa Cruz Museum of Art and History</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
</div>

###### Technique: Photogrammetry



###     [5.1.5. Glass Ornament](#5.1.5_glass_ornament)

**Significant Characteristics:**

Transparent, shiny, fine surface detail, internal and external features.

**Potential Digitization Technique(s):**

Photogrammetry with polarized light + dulling spray, structured light scanning, x-ray CT.

**Digitization Complexity:**  

4/5.

**Examples:**



<p id="gdcalert14" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text13.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert15">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text13.png "image_tooltip")
 \
[Blaschka "Football Sea Squirt" (CT & Photos)](https://sketchfab.com/models/321092996865487eae77bf232b7f3f7d) by [ARC-3D](https://sketchfab.com/ARC-3D)—[Peter Fried, US](https://sketchfab.com/ARC-3D)—x-ray CT and photogrammetry.



<p id="gdcalert15" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text14.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert16">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text14.png "image_tooltip")


[Roman Glass Vase](https://sketchfab.com/models/92621c63c8a047d2aa879ac927b12687) by [Art History in 3D at the University of Miami, US](https://sketchfab.com/umiamiarh)—photogrammetry.



###        [5.1.6. Statue](#5.1.6_statue)

**Significant Characteristics:**

Medium sized (~2 to 20 feet), internal and external features, complex self-occluding forms.

**Potential Digitization Technique(s):**

Photogrammetry, structured light scanning (depending on subject size), x-ray CT (depending on subject size), LiDAR.

**Digitization Complexity:**

2/5.

**Examples:**



<p id="gdcalert16" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text15.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert17">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text15.png "image_tooltip")


[Maternal affection](https://sketchfab.com/models/fcbd7acf26814169a5bd3a6ca9cb2003) by [Fitzwilliam Museum, UK](https://sketchfab.com/fitzwilliammuseum)—structured light scanning.



<p id="gdcalert17" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text16.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert18">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text16.png "image_tooltip")


[Statue of A’a](https://sketchfab.com/models/e4dd6d342fa044b99732b484985797b6) by [The British Museum, UK](https://sketchfab.com/britishmuseum)—photogrammetry.



###   [5.1.7. Building Interior and Exterior](#5.1.7_building_interior_and_exterior)       

**Significant Characteristics:**

Large, immovable, multiple materials.

**Potential Digitization Technique(s):**

Photogrammetry, LiDAR.

**Digitization Complexity:**

2/5.

**Examples:**

<div class="sketchfab-embed-wrapper">
    <iframe title="A 3D model" width="640" height="480" src="https://sketchfab.com/models/17bd8188447b48baab75125b9ad20788/embed?preload=1&amp;ui_controls=0&amp;ui_infos=0&amp;ui_inspector=0&amp;ui_stop=0&amp;ui_watermark=1&amp;ui_watermark_link=1" frameborder="0" allow="autoplay; fullscreen; vr" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/3d-models/sy-carola-point-cloud-17bd8188447b48baab75125b9ad20788?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">SY Carola (point cloud)</a>
        by <a href="https://sketchfab.com/ScottishMaritimeMuseum?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Scottish Maritime Museum</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
</div>

###### Technique: LiDAR + photogrammetry


<div class="sketchfab-embed-wrapper">
    <iframe title="A 3D model" width="640" height="480" src="https://sketchfab.com/models/feb9ad17e042418c8e759b81e3b2e5d7/embed?preload=1&amp;ui_controls=0&amp;ui_infos=0&amp;ui_inspector=0&amp;ui_stop=0&amp;ui_watermark=1&amp;ui_watermark_link=0" frameborder="0" allow="autoplay; fullscreen; vr" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/3d-models/the-great-drawing-room-feb9ad17e042418c8e759b81e3b2e5d7?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">The Great Drawing Room</a>
        by <a href="https://sketchfab.com/TheHallwylMuseum?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">The Hallwyl Museum (Hallwylska museet)</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
</div>

###### Technique: Photogrammetry.


### [5.1.8. Performance](#5.1.8_performance)

**Significant Characteristics:**

Comprising a physical performer and accompanying motion, potentially also costumes and props.

**Potential Digitization Technique(s):**

Photogrammetry, structured light scanning (for the performer), motion capture (for the performance).

**Digitization Complexity:**

5/5.

**Example:**



<p id="gdcalert20" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text19.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert21">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text19.png "image_tooltip")


[新莊地藏庵頭前庄官將首：喊班 (Xinzhuang Jizo head in front of Zhuang officials: shouting class)](https://sketchfab.com/models/14b63c40815d4ceebe4e88852961d5cb) by [中國科大數媒系─表演捕捉與動畫科技研究室 (Department of Digital Media, University of Science and Technology of China-Performance Capture and Animation Technology Research Lab)](https://sketchfab.com/CuteDmd-MocapLab)—3D modeling, motion capture.

(_target_)

## [5.2. Cultural and Other Non-Legal Considerations](#5.2_cultural_and_other_non-legal_considerations)

There may also be non-legal factors to consider when selecting works to digitize and make available to the public.[^44] While these factors may vary widely depending on the nature of your collection, one factor to consider is how you can effectively propagate an awareness of the cultural context that created a work in the first place.

The best way to address these concerns will vary widely, depending on the nature of the cultural resources and the sensitivities involved. In some cases, it may be beneficial to consult with the cultural originators (or their descendants) of a work to identify concerns that the communities may have in relation to digitization and Open Access programs.

One innovative approach to cultural resources originating with indigenous communities has been the [Traditional Knowledge (TK) labelling system](http://localcontexts.org/tk-labels/). The TK label system makes it easy for indigenous communities to communicate context and preferred uses to others. These labels are not intended to be legal restrictions on users. Instead, they are designed to communicate additional cultural context to users interested in incorporating that context into their own exploration of the resource. TK labels can easily be incorporated into the presentation of the digitized version of the cultural asset.[^45]



##    [5.3. Navigating Copyright and the Public Domain](#5.3_navigating_copyright_and_the_public_domain)

Copyright status is another factor to consider when identifying cultural resources to make available to the public.[^46] Although copyright law varies from country to country, this section is intended to provide a working overview of the main concepts to consider. This should make it easier to coordinate with the legal department of your institution or outside legal experts to identify works unencumbered by copyright restrictions. In most cases, it will be easier to start working with items that are in the public domain, which means that their use is not restricted by copyright law.

Generally speaking, copyright automatically protects creative works from the moment of creation for a period of time. While that “period of time” has evolved over the years, today in most places the term of copyright protection is the life of the author plus 70 years.[^47] Although it can sometimes be complicated to calculate the term of copyright protection for an individual work created in the past, as a general rule of thumb, the older a work is the more likely it is to have entered the public domain.[^48] For example, in the United States most works created before 1924 have entered the public domain. As a group, archeological objects are also likely to be in the public domain.

While the category of “creative works” eligible for copyright protection when they were created is broad and will likely include most works held by GLAM institutions, there are important exceptions to be aware of. In most cases, copyright does not protect natural specimens like plants, insects, or fossils. Nor does it protect purely functional items, such as a collection of machines or other mechanical items. These items are often in the public domain from the moment they come into existence. Your legal partners will be able to assist in helping identify collections that may be excluded from copyright protection.

Once the period of protection for a work has expired, it enters the public domain. There it joins other works that were never protected by copyright in the first place. Public domain status is important for both the digitizing institution and the public. For the digitizing institution, works in the public domain can be digitized without raising copyright concerns. For the public, an object in the public domain is free to be re-used without fear of violating copyright law.



###        [5.3.1. Copyright in Digitized Objects](#5.3.1_copyright_in_digitized_objects)


Digitizing an in-copyright work without permission will likely infringe on the rights of the copyright holder. In light of this, it may be wise to begin digitization with works that are already in the public domain.

For works already in the public domain, there have been questions as to whether the act of digitizing a cultural resource that is in the public domain creates a copyright in the “new” digital copy. The United States courts have been reluctant to recognize a new copyright interest in a digitized public domain cultural resource.[^49] As of this writing, the treatment of digitized public domain works in the EU is more varied.[^50] However, the new Article 14 of the EU Copyright Directive[^51] appears to move away from endorsing the idea of granting a new copyright interest in the digitization of public domain works (specifically works of visual art). National implementation of this directive will clarify some of the specific rules around digital versions of public domain objects. Section 7.7 suggests using licensing best practices to further clarify that the digitizing institution neither has nor claims additional legal rights to the digitized cultural artifact.



###        [5.3.2. Copyright in Metadata](#5.3.2_copyright_in_metadata)

In addition to the digitized cultural artifact itself, many institutions will make para- and metadata about the object available to the public. This metadata may include straightforward technical information, such as the work’s dimensions, year of creation, or physical location in the institution itself. It may also include more nuanced information, such as prose written by a curator providing context and background information.

As a general matter, individual pieces of technically descriptive information—facts about an individual cultural object—will not be protected by copyright.[^52] In contrast, written descriptions and other prose-based context will be protected by copyright.[^53] Section 7.4 suggests licensing best practices for this type of information.



###        [5.3.3. Other Legal Rights](#5.3.3_other_legal_rights)

Although copyright is often the first legal consideration for Open Access digitization projects, the act of digitizing and releasing digital versions of objects in your collection can raise a number of other potential legal challenges. As noted earlier, objects may be encumbered by moral rights, cultural heritage laws, or other non-copyright-based restrictions on use. Your legal collaborators may be able to help you identify additional rules to be aware of when selecting works for digitization and dissemination.

In doing so, it is important to avoid the temptation of the “easy no.” When digitizing large numbers of physical items, it can be easy to imagine edge scenarios where some specific use of the digitized version of the item could violate a law or right (e.g., “what if someone took a digitized version of this crown, created a replica, and tried to pass themselves off as a monarch?”). When faced with this possibility, it can be tempting to broadly exclude categories of works from a digitization program. Avoid this trap by fully articulating the nature of the concern. Also, explore if the concern is specific to 3D models. In many cases the same concern could, at least in theory, be applied to 2D images as well. If your institution is comfortable making 2D images of an object available to the public, in most cases it should also be comfortable making 3D versions available as well.

Finally, in many cases, including a disclaimer that indicates that the files are being released to be used “for any lawful purpose” can address some of these concerns from the perspective of the institution. These types of disclaimers are discussed in Section 7.7.1.1.



# [6. Digitize](#6_digitize)
##    [6.1. 3D Scanning](#6.1_3d_scanning)

This section will provide you with best practices for 3D digitization. It will not suggest a single workflow because there is no universal workflow for capturing cultural resources in 3D. Most resources are unique in size, shape, material, handling guidelines, accessibility, and portability. Most GLAM organizations and digitization projects are unique in their staffing, funding, goals, and audiences.

Additionally, and despite a huge amount of 3D data being produced by GLAM organizations,[^54] there are surprisingly few projects that share common standards and best practices.[^55]

Instead of searching for a single 3D digitization solution, it is more practical to explore existing guidelines for 3D digitization and consider their relevance to your project goals. It should then be possible to embed decision-making breakpoints and opportunities to capture paradata snapshots within your digitization project planning. Some points to consider are shared in this section.



###        [6.1.1. Do Your Research](#6.1.1_do_your_research)
Spending time to research existing workflows, case studies, and advice will save you time in the long run. Read academic papers but also visit or subscribe to specialized blogs and forums, and follow experts and amateurs alike on social media. Piece together a knowledge base that is suitable to your goals before you begin and make a note of resources you feel will be valuable to revisit later. Don’t be afraid to reach out to colleagues, manufacturers, and software developers directly for specific advice—it can save you hours of searching and maybe even some money too.

Below are a few online communities you may wish to consider joining, as well as a general reading list:

**Community Groups**

[IIIF 3D Community Group](https://iiif.io/community/groups/3d/)

[Community Standards for 3D Preservation (CS3DP)](https://groups.google.com/forum/#!forum/community-standards-for-3d-data-preservation-cs3dp)

[Europeana 3D Task Force](https://pro.europeana.eu/project/3d-content-in-europeana)

[LIB3DVR](https://lib.vt.edu/research-learning/lib3dvr.html)

[CLIR 3D/VR](http://vrpreservation.oucreate.com/Colloquium/) \
[3D Scanning Users Facebook Group](https://www.facebook.com/groups/3dsug/)

[Open Heritage 3D](https://openheritage3d.org/)

[Share3D](https://share3d.eu/)

**Reading Material**

[Cultural Heritage Spotlights on the Sketchfab Blog](https://sketchfab.com/blogs/community/category/community-story/cultural-heritage)

[Sketchfab Cultural Heritage Users Survey Results 2019](https://tinyurl.com/skfbchsurveyresults)

[Europeana 3D Task Force Report](https://pro.europeana.eu/files/Europeana_Professional/Europeana_Network/Europeana_Network_Task_Forces/Final_reports/3D-TF-final%20report.pdf)

[British Art Studies Issue 6: Disciplining the Digital](http://britishartstudies.ac.uk/issues/issue-index/issue-6/virtual-reproduction)

[ReACH Dialogue](https://www.vam.ac.uk/research/projects/reach-reproduction-of-art-and-cultural-heritage) - [Copy Culture: Sharing in the Age of Digital Reproduction PDF](https://vanda-production-assets.s3.amazonaws.com/2018/06/15/11/42/57/e8582248-8878-486e-8a28-ebb8bf74ace8/Copy%20Culture.pdf)

[Advice on 3D from National Swedish Heritage Board](https://www.raa.se/in-english/outreach-and-exhibitions)

[The London Charter](http://www.londoncharter.org/)



###        [6.1.2. Capture the Best Result You Can And Work Transparently](#6.1.2_capture_the_best_result_you_can_and_work_transparently)

No matter how well resourced and organized, your 3D digitization project will likely be limited in some way. The equipment and time available to you will largely dictate the resolution and fidelity of your 3D output. Be transparent about those limitations to your users. Publishing lower-resolution and even incomplete 3D scans is fine as long as you also make it clear to audiences what it is they are viewing and how it was made.

###   [6.1.3. Document Your Process As Thoroughly As Possible](#6.1.3_document_your_process_as_thoroughly_as_possible)

Following on from the previous point, and to re-assert the importance of meta- and paradata, record the details of your digitization and post-production process as much as possible. From the moment you begin your work, make note of the equipment you are using, decisions you are making, and the circumstances of the capture environment. Continue to document decisions made during processing and post-production and aim to publish this information at the same time as the 3D models.

###   [6.1.4. Plan For Mistakes And Technical Issues](#6.1.4_plan_for_mistakes_and_technical_issues)

Things don’t always go according to plan, but you can prepare your workflow to cope with this. Give yourself more time than you need to conduct digitization. Plan extra and backup digitization sessions. If you are new to a 3D digitization process, budget time to make tests and get familiar with your tools. Unless your work is highly specialized, you will no doubt find an answer online to any unexpected roadblocks you experience.


### [6.1.5. Archive Input Data And Project Files As Well As Output 3D Data](#6.1.5_archive_input_data_and_project_files_as_well_as_output_3D_data)

In an ideal world, all the data that is captured and produced during digitization would be available and archived in a way that accords with best practices. While this can quickly run to terabytes of data, making input data and project files available means other people can verify and build on your work. It will also allow you to go back to make additional uses of your scanning efforts as new technology develops. Long-term data storage and security should be considered during your project planning.

Cultural sector collections management, digital asset management, and digital preservation providers need to develop further capabilities to catalogue, process, present, store, transform, and deploy 3D data and models. Most of these systems are currently oriented toward 2D digital images, accompanying metadata, and—increasingly—video. Many of the technological advances and communities of practice for 3D began in industries outside the cultural realm, such as gaming, manufacturing, and multimedia production. Time-based media and software preservation systems are being used with increasing adoption as more of cultural and content production is digital-first. Institutions should work with the industry systems providers to test and build capacity for 3D data and models, along with working in collaboration with professional communities of practice. Common and core functionalities include the aforementioned internal systems requirements, along with external functionalities such as browser-based display and download from collections online; deployment and distribution to third-party databases or applications through batch processes or automated APIs; and export and migration to future platforms.



##  [6.2. Data Structures](#6.2_data_structures)

###        [6.2.1. Metadata and Paradata](#6.2.1_metadata_and_paradata)

Metadata related to 3D models of cultural resources includes information about the 3D file(s) and information regarding the cultural resource itself. The paradata explains how a 3D model was generated and details decisions that were made during this process. Meta- and paradata make a given 3D model more valuable and re-usable: If audiences better know what they are viewing or downloading, they are better able to understand it and incorporate it into their own plans.

It is not currently possible to reliably embed extended meta- and paradata within most 3D file formats. While some file formats like X3D offer the option to write additional information into the 3D file itself, the format is not widely supported in other 3D software or platforms—and when a file is converted to another format, the data is often lost. This makes X3D an interesting candidate for archival data but not so valid as a format for dissemination through an Open Access program.

A simple approach to connecting metadata to a 3D model is to publish it separately from the model and/or provide links to it. This might take the form of one or all of the following:

*   A text file within the downloadable 3D data archive
*   A link on the same page as the 3D model
*   Machine-readable tags (where supported)
*   An online database that is accessible via API or a web interface

Whatever form you decide on, do not be overly concerned with the idea of your 3D data existing separately from its detailed metadata. End users of your 3D data will inevitably edit, separate, or remove metadata when it is not deemed relevant to their re-use of your 3D models.

What is important is to make a “best effort” at the point of initial interaction, to provide as much context to your 3D model as possible. A nice example of this approach is the presentation of the 3D model [The Grandfather of Europe by AD&D 4D](https://sketchfab.com/3d-models/the-grandfather-of-europe-granada-spain-decf3d333d9d4345a35ac5d524d71e1f) on Sketchfab:

*   The 3D model is present with a descriptive title, including the cultural resources location.
*   A summary description is presented alongside in both English and Spanish.
*   The description includes a Digital Object Identifier (DOI)[^56] badge from zenodo.com that links a persistent online record pertaining to the digital file, as well as downloadable data packages.
*   The model is categorized correctly in the Sketchfab system.
*   The model is presented with extensive descriptive, machine-readable tags.
*   There are extensive informative annotations on the model itself.

What constitutes a complete metadata set and best practice for associating it with a 3D model is not a settled matter, and several organizations are working toward building consensus.[^57] What metadata you capture and publish will largely depend on what is already available (e.g., an existing cultural resource object record) and what you have the opportunity and capacity to record during your 3D creation workflow. There is no clear right or wrong regarding metadata; rather, there are gradations of light to heavy, sparse to complete, and this should be made clear wherever the metadata is published. A bare minimum might be a description of what the cultural resource represented by the 3D model is, a technical description of the 3D file, and a description of the workflow by which it was captured or created.

Among the mature 3D digitization initiatives for cultural heritage, the [Smithsonian 3D Metadata Model](https://dpo.si.edu/blog/smithsonian-3d-metadata-model) offers one of the most complete attempts at defining a metadata scheme for cultural heritage 3D, based on extensive experience digitizing resources from multiple collections.

###     [6.2.2. Data Files](#6.2.2_data_files)

The input and project files that you offer under Open Access will vary depending on your capture, processing, and post-production methods. The output and derivative 3D files will also vary depending on your project goals.

By way of example, let’s consider a 3D model generated using a photogrammetry pipeline:

**Input Files**

Digital images.

**Project Files**

Photogrammetry software project file.
3D editor software project file (if the workflow included a post-production stage).

**Output and Derivative 3D Files**

The following list is not exhaustive and, depending on your project goals, there may be other 3D file formats that suit your needs. It is recommended that you check which file formats your destination 3D viewer supports, as well as what download formats are most usable by your primary audience(s).

You do not need to choose only one output file format. Publishing the same 3D model in a variety of formats increases the chance of uptake by certain communities. Suggested file formats for you to create are listed below with a summary of their use cases.

**X3D**

As one of the only 3D [ISO/IEC internationally ratified standard](https://www.web3d.org/standards/number/19775-1) formats, X3D is a good choice for archival use, but for wider dissemination, other formats should be considered.

**OBJ**

An open source file format that is widely supported in common 3D editing software. It is usually associated with a separate material (.MTL) file and separate texture map file(s) (.JPG, .PNG).

**FBX**

A proprietary file format often used in film, animation, and interactive game production that supports embedded textures and animations.

**STL**

A file format specific to 3D printing. It does not support vertex or UV color mapping.

**GLTF, USDZ**

Two newer open 3D interchange formats that support embedded animations, color mapping, and material options. Support for both formats is growing across 3D editing tools for film, animation and interactive game production, as well as AR and VR tools. Android devices that support ARCore are able to display GLTF in a native [AR Scene Viewer](https://developers.google.com/ar/develop/java/scene-viewer), and likewise iOS devices can natively display USDZ in [AR Quicklook](https://developer.apple.com/augmented-reality/quick-look/).

Duplicating or exporting a 3D model in multiple formats will of course take more time and significantly increase data storage requirements. This effect is compounded if 3D models at multiple resolutions for each file format are required. One approach to mitigate such issues might be to produce and maintain high-resolution “master” projects and 3D models files, only creating derivatives as and when they are required, it being even better if this process can be automated.

###     [6.2.3. Data Packages](#6.2.3_data_packages)

By deliberately choosing a combination of 3D file formats, data resolutions, and linked meta- and paradata, it is possible to build “data packages” aimed at specific audiences. As part of digitization project planning, it is likely a good exercise to define target data packages and budgeting post-production resources to their preparation. If you are not sure of the best data package for your audience, it will behoove you to reach out to that audience before beginning digitization.

Three example data packages follow:

**Researchers**

*   Input data
*   Project files
*   High-resolution archival 3D data, X3D file, high -resolution texture maps (16384x16384 pixels)
*   Extensive meta- and paradata

**Students**

*   Optimized derivative 3D data, STL and OBJ files, medium-resolution texture maps (4096x4096 pixels)
*   Curriculum-related meta- and paradata

**AR and VR Developers**

*   Highly optimized derivative 3D data—e.g., GLTF, USDZ, low-resolution texture maps (1024x1024 pixels)
*   Basic metadata

#   [7. Disseminate](#7_disseminate)

##    [7.1. Review Goal-Setting](#7.1_review_goal-setting)

At this stage of a project, when the 3D models have been produced, documented, and archived locally, there is a natural break in activity, which presents an opportunity to review the goals that have been previously set for your project.

Digitization projects can take a long time to complete and new examples of dissemination best practice may be available, or even new software, services, or platforms may have sprung up that best serve your project goals. It is at this stage that you should look outside of your organization and review the best ways to reach your identified audience(s).



##    [7.2. Publish as Interactive 3D for Browsing Audiences](#7.2_publish_as_interactive_3d_for_browsing_audiences)

As described in the “What is a 3D Model?” section, for an audience to truly experience a digital 3D model, it needs to be interactive. At a very basic level, this means an audience member must be able to turn or tumble a 3D model to view the model from different angles and zoom in and out to get a closer look or broader overview of the resource. While this was previously only possible via dedicated applications running on specialized hardware, thanks to modern web standards like WebGL, it is possible to offer proper 3D interactive experiences in any modern browser. That means the model is accessible to all users, even those without the technical expertise to use their own 3D modeling software.

Ongoing technical developments—for example, in the smartphone and head-mounted display industries—make it easier than ever to offer different kinds of 3D model-based experiences. 3D models can be manipulated on screen via a mouse and keyboard or a touchscreen interface, as well as via the more physically engaging interactions of virtual and augmented reality.

Publishing a 3D model of a cultural resource without any context is unlikely to be of particular use to your audience. Thankfully, as with most other web-based content, 3D can be published alongside other information (e.g., text, images, video, audio) in a web page, which will likely go some way to satisfying your digitization project goals.

A step further is to embed contextual and descriptive information within the 3D viewer itself in the form of 3D annotations—that is to say, hotspots or points of information attached directly to the surface of a 3D model. When clicked or tapped, these hotspots display or play back information, most likely related to the point or area on the 3D model to which they are attached.

In this manner, it is possible to create interactive 3D tours of digitized cultural resources as a proxy for in-gallery experiences like guided object handling.



<p id="gdcalert21" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text20.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert22">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text20.png "image_tooltip")


[Quiriguá Zoomorph P Annotated Tour by University of South Florida Libraries](https://sketchfab.com/models/d53a8c1dd53f44c282c4bb2b56f26d26).



###        [7.2.1. Notes on Digital Display](#7.2.1_notes_on_digital_display)

The same 3D model can generally be displayed using different 3D viewing software (often referred to as a _3D viewer_). 3D viewing software is different from 3D editing software (often referred to as a _3D editor_) in that the primary purpose or functionality is to simply display 3D data on screen as opposed to editing or converting it in any significant way.

Each software reads the 3D data file(s) and displays it as pixels on the screen—this is known as _rendering_. The part of a software that calculates what the digital file should look like on screen is known as a _rendering engine_. Different rendering engines support different file types and file-specific data. As a result, the same 3D file can look very different in different 3D viewers. That means you will be making choices about how people view the files you create, not just how you will create them.



<iframe name="Smithsonian Voyager" src="https%3A%2F%2F3d-api.si.edu%2Fvoyager%2F3d_package%3Ad8c6393a-4ebc-11ea-b77f-2e728ce88125" width="800" height="450" allowfullscreen="true"></iframe>

###### _Baluster vase, from a five-piece graniture_ rendered in the Smithsonian Institution's Voyager 3D viewer

<div class="sketchfab-embed-wrapper">
    <iframe title="A 3D model" width="640" height="480" src="https://sketchfab.com/models/76a3f7bf75d049458dfaa48aa342e0b8/embed?preload=1&amp;ui_controls=0&amp;ui_infos=0&amp;ui_inspector=0&amp;ui_stop=0&amp;ui_watermark=1&amp;ui_watermark_link=1" frameborder="0" allow="autoplay; fullscreen; vr" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/3d-models/baluster-vase-from-a-five-piece-garniture-76a3f7bf75d049458dfaa48aa342e0b8?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Baluster vase, from a five-piece garniture</a>
        by <a href="https://sketchfab.com/Smithsonian?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">The Smithsonian Institution</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
</div>

###### _Baluster vase, from a five-piece graniture_ rendered in the Sketchfab 3D viewer



###        [7.2.2. Choosing an Online 3D Viewer](#7.2.2_choosing_an_online_3d_viewer)

Deciding on which 3D viewer you use to display your 3D models online will largely depend on your project goals, your organization’s policies for using third-party platforms, and capacity for ongoing technical support and development.



####            [7.2.2.1. Self-Hosted Storage and Display Solutions](#7.2.2.1_self-hosted_storage_and_display_solutions)[^58]
Self storage and hosting can offer greater control over how our 3D models are presented (e.g., custom interfaces) and how people interact with and access them (e.g., only via your organization’s website). These benefits come at the expense of maintaining web servers and application code.

* [3DHOP](http://vcg.isti.cnr.it/3dhop/)

* [Smithsonian Voyager](https://github.com/Smithsonian/dpo-voyager)

* [Universal Viewer](https://universalviewer.io/)



####            [7.2.2.2. Hosted Storage and Display Solutions](#7.2.2.2_hosted_storage_and_display_solutions)

Using a hosted 3D viewer service is the quickest route to interactive online publication for your 3D data. Generally, using a hosted 3D viewer will require uploading your data to third-party-owned web servers and agreement to platform-specific terms of use. Benefits of using a hosted storage and display solution include reduced technical and staff overheads for you and your organization, and dissemination of your 3D models to an existing, 3D literate community.

* [Google Poly](https://poly.google.com/)

* [Sketchfab](http://sketchfab.com/)

* [Wikimedia Commons Viewer](https://blog.wikimedia.org/2018/02/20/three-dimensional-models/)

* [model-viewer](https://modelviewer.dev/)



##  [7.3. Publish the 3D Data for Download](#7.3_publish_the_3d_data_for_download)

Publishing a cultural resource as an interactive 3D model goes a long way to making 3D models findable and accessible. The next step is to make the 3D data available for download (hopefully alongside an interactive viewing experience). Published 3D data should be in an interoperable format—i.e., a 3D file that can be opened and edited in a piece of software. Publishing 3D data in an inaccessible format—for example, as a downloadable 3D PDF or self-contained app—is essentially a dead end for data re-use.

The simplest way to make data available for download is as a .zip archive hosted somewhere online. Whatever files are offered for download, it should be made clear what the data represents, what format it is in, and what license it is being offered under, prior to the download being initiated. Additionally, it is good practice to include this information in the download archive itself as a plain text file.

Publishing 3D data for download assumes some level of skill in the target audience regarding 3D. The “data package” approach mentioned previously will go a long way to making your published data attractive to a given audience. Where necessary, you should consider guiding audiences to recommended software and activities that match the data you are offering.

Finally, keep in mind the difference between a “self-serve” approach and a managed approach to download.

“Self-serve” means that anyone may easily download and save 3D data locally without contacting the publisher, although the end user may be required to sign in or up to a service to enable this ability. This is the most accessible and fastest route for someone to receive your 3D data.

A managed approach in which an end user must, for example, request 3D data via email and wait for a reply each time they wish to make a download can allow for greater control over data dissemination but could also appear to be a form of gatekeeping.



##    [7.4. Publish Derivative Content](#7.4_publish_derivative_content)

Publishing images, animations, and video derived from 3D models can be a helpful complement to the 3D data or viewer itself. Using media and media platforms that audiences are more familiar with can be an enticing gateway to engaging with the 3D data itself. Some examples:

**High-Resolution Image Renders**



<div class="sketchfab-embed-wrapper">
    <iframe title="A 3D model" width="640" height="480" src="https://sketchfab.com/models/b9766d88112141369b170070fb973c96/embed?preload=1&amp;ui_controls=0&amp;ui_infos=0&amp;ui_inspector=0&amp;ui_stop=0&amp;ui_watermark=1&amp;ui_watermark_link=0" frameborder="0" allow="autoplay; fullscreen; vr" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/3d-models/king-gustav-vasas-helmet-with-a-gilt-crown-b9766d88112141369b170070fb973c96?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">King Gustav Vasa&#39;s Helmet with a Gilt Crown</a>
        by <a href="https://sketchfab.com/TheRoyalArmoury?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">The Royal Armoury (Livrustkammaren)</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
</div>
(_target_)


**360 “Turntable” Animated GIFs**

![King Gustav Vasa Helmet as 360 turntable gif](images/gustav_helmet_360.gif "King Gustav Vasa Helmet as 360 turntable gif")


**Screen Capture Video Exploring a 3D Model**

![King Gustav Vasa Helmet as screen capture image](images/gustav_helmet_annotation.png "King Gustav Vasa Helmet as screen capture image")




##    [7.5. Availability and Findability](#7.5_availability_and_findability)

Publishing the 3D data online in any form does not signify the end of an Open Access digitization project. An element of promotion and making the invitation to re-use 3D data clear to target audiences is essential to increase engagement with any Open Access program. Some select considerations for publishing your 3D outputs are laid out below. For guidelines to improve the findability, accessibility, interoperability, and re-use of any kind of digital assets, consider reviewing the [FAIR Principles](https://www.go-fair.org/fair-principles/).



###        [7.5.1. SEO](#7.5.1_seo)
Good search engine optimization (SEO) of web pages featuring your 3D models will help people discover your project online. If somebody performs a web search for “[your organization name] Open Access” or “[term related to cultural resource] 3D model” (as two basic examples), they should be pointed in the right direction.



###        [7.5.2. Data Interfaces/APIs](#7.5.2_data_interfaces_apis)
Making your data available via both human and machine interfaces—that is to say browsable web pages as well as APIs—allows for different forms of engagement. The former caters to individuals and individuals presenting your work to a group (e.g., teachers presenting to a classroom of students); the latter can plug your cultural 3D data into entire digital platforms and get it in front of potentially massive 3D-oriented communities.

![Screenshot of the Sketchfab - Spark API integration](images/sketchfab_facebook_api.png "Screenshot of the Sketchfab - Spark API integration")

###### Browsing 3D models hosted on sketchfab.com in Facebook’s Spark AR application (used to make Instagram AR filters) is made possible by an [API integration](https://sparkar.facebook.com/ar-studio/learn/documentation/docs/ar-library/).

[Sketchfab API](https://sketchfab.com/developers)

[Smithsonian Institution’s Open Access Developer Tools](https://www.si.edu/openaccess/devtools)

[Google Poly API](https://developers.google.com/poly/develop/api)

##    [7.6. Active Promotion](#7.6_active_promotion)

Once 3D data has been published, it should be a priority to advocate for its re-use by colleagues within your GLAM organization as much as by your target audiences. Teach people how 3D models can be embedded in object collection pages, exhibition marketing, in-gallery interactive—wherever it’s relevant. Make a special effort to support marketing and social media teams in understanding how they can draw on 3D model resources to create engaging content tailored for audiences where they already exist—i.e., digital newsletters, blog articles, and social media platforms.



###        [7.6.1. Partnerships](#7.6.1_partnerships)

Any strategy for disseminating 3D content online should define basic partner platforms to help deliver the same 3D content in as many ways as possible. Different online platforms offer varying functionality and often cater to specific audiences and choosing the right platforms.

The practicalities of posting the same 3D models on multiple platforms necessitate ongoing additional staff time or a one-time investment in building an automated workflow.

Some platforms to consider:



*   [Google Poly](https://poly.google.com/) -  “Explore the world of 3D.”

*   [Morphosource](https://www.morphosource.org/) -
“MorphoSource is a project-based data archive that allows researchers to store and organize, share, and distribute their own 3d data.”

*   [Mozilla Hubs](https://hubs.mozilla.com/) -
“Share a virtual room with friends. Watch videos, play with 3D objects, or just hang out.”

*   [My Mini Factory/Scan the World](https://www.myminifactory.com/scantheworld/) -
“Enabling a decentralized ecosystem for 3D creatives, one step at a time.”

*   [Sketchfab](https://sketchfab.com/) -
“Sketchfab is empowering a new era of creativity by making it easy for anyone to publish and find 3D content online.”
*   [Thingiverse](https://www.thingiverse.com/) -
    “MakerBot's Thingiverse is a thriving design community for discovering, making, and sharing 3D printable things.”

*   [Wikimedia Commons](https://commons.wikimedia.org/) -
“We’ve enabled a new feature that allows you to upload three-dimensional (3D) models.”

##    [7.7. Legal Infrastructure](#7.7_legal_infrastructure)

It is critical to include legal information about digitized cultural assets to users. Without this information, users will be unable to make full use of digitized assets.



###        [7.7.1. Licensing Best Practices (Digitizations of Cultural Objects)](#7.7.1_licensing_best_practices_digitizations_of_cultural_objects)

As described in Section 5.3, many jurisdictions do not—or soon may not—recognize an additional copyright interest in digitizations. As a result, in many cases—although certainly not all—digitizing institutions will not have a copyright interest in the digital file that represents a cultural object. In light of this ambiguity, institutions should use licenses to clarify how users may make use of files included in Open Access initiatives.



####            [7.7.1.1. Legal Agreements](#7.7.1.1_legal_agreements)

The current best practice is to use the [Creative Commons CC0 mark](https://creativecommons.org/share-your-work/public-domain/cc0/) on all Open Access digitized objects. The CC0 mark is designed to waive any copyright interest jurisdictions may grant your institution in the digitizations themselves. This includes the jurisdiction where your institution is based, as well as jurisdictions where your user may be based. Using the CC0 mark makes it clear to all users that the digitizing institution does not claim additional legal rights in a digitized object in the relatively unlikely event that those rights do exist.

Note that using the CC0 mark does not require your institution to warrant that the digitized cultural object itself is in the public domain.[^59] The CC0 mark merely indicates that the digitizing party will not claim additional ownership or control over the file. To the extent that the digitizing institution has additional information about the copyright status of the cultural object, [RightsStatement.org](https://rightsstatements.org/page/1.0/?language=en) provides standardized ways to describe that status outside the bounds of formal legal tools.

It is not currently considered best practice to place attribution, non-commercial, or educational-use-only restrictions on digitized cultural objects. These restrictions can be hard for users to interpret consistently and may unintentionally discourage the types of uses you hope to encourage. It is also likely that copyright-based use restrictions placed on public domain works are not enforceable, further complicating the legal status of the files and discouraging use.

While it is best practice for an institution to share provenance information about a cultural object, it is acceptable for a digitizing institution to include a disclaimer that the provenance information provided may not be accurate or complete, and that users should not necessarily rely on it when making rights status determinations. A disclaimer can be used to indicate that the institution is making the works available for “all legal purposes” or “any legal purpose,” which may address concerns about edge cases where bad-faith users could make use of the works in a way that violates specific laws.

Institutions should also avoid the impulse to impose additional restrictions on users via terms and conditions attached to a distribution platform or even individual files. These types of restrictions complicate downstream uses because it can be hard to determine if any individual user is legally bound by them. Similarly, these types of restrictions may create unreasonable—and unenforceable—expectations about the type of control your institution will have on the use of the files.



####            [7.7.1.2. Non-Legal Indicators](#7.7.1.2_non-legal_indicators)

While it is not best practice to impose legal restrictions on the use of digitized cultural objects, it is acceptable to make non-binding requests of those users. This is especially true in the case of restrictions—such as a requirement of attribution—that the institution is unlikely to actively enforce through legal mechanisms. It is critical that the institution makes it clear that it understands these requests to be non-binding, and not to cloak them in quasi-legal language or presentation styles.

For example, institutions can request that users use a standardized way to communicate the source of the digitized object to others. They can also provide an easy way for users to report their use back to the institution. Although these requests are not legally enforceable, many users will happily comply with these types of requests from digitizing institutions.

These best practices have generally been developed for cultural objects in the public domain. If you have digitized objects that are protected by copyright, best practice is to clearly communicate the terms of that agreement with any users as thoroughly as possible.[^60]



###        [7.7.2. Licensing Best Practices (Metadata and Descriptions)](#7.7.2_licensing_best_practices_metadata_and_descriptions)

Section 5.3 explains that digitizing institutions may have more legal rights in information such as metadata and descriptions of digitized cultural objects than digitized versions of the objects themselves. Nonetheless, it is best practice for digitizing institutions to license all metadata and descriptions using the CC0 license.

Other permissive licensing structures (such as the attribution requirement of a CC BY license) can create unintended challenges for downstream users of metadata and descriptions. Metadata and descriptions will often be used in large-scale analysis or other data-driven investigations. Determining the proper way to comply with even a seemingly straightforward attribution requirement in a CC BY license can present disproportionate challenges to users, discouraging the types of uses you may hope to encourage.

As with the digitized objects themselves, nothing in the use of CC0 prevents the digitizing institution from requesting attribution or feedback on re-use. The difference between a request and a legally binding demand increases the amount of flexibility available to the user.


###        [7.7.3. Presenting Legal and Quasi-Legal Language](#7.7.3_presenting_legal_and_quasi-legal_language)

Institutions should strive to present legal and legal-adjacent information in as approachable a manner as possible, and to streamline its presentation to the public. While licenses, warranties, and requests are important, they can also be intimidating to users without a background in legal text. The mere presence of “legalese” can act as a barrier for perfectly legitimate uses. Successful Open Access projects are inviting to users. While it may feel like adding one additional clause to address an edge case is responsible stewardship or lawyering, the cost of doing so may be reducing the types of engagement that motivate the initiative in the first place.


###        [7.7.4. Cultural Labelling](#7.7.4_cultural_labeling)

Many cultural objects have other considerations or cultural restrictions that are important to communicate to users. While these considerations and restrictions may not be legally binding, many users will benefit from being aware of them. Cultural sources may also be more supportive of digitization and dissemination efforts when they are accompanied by this type of information.

Local Contexts’ [Traditional Knowledge labels](http://localcontexts.org/tk-labels/) help to facilitate the communication of these types of non-legal use considerations. The labels give cultures that created the works a way to clearly communicate important context to users. They also give users a straightforward way to identify these restrictions and incorporate them into their application.



# [8. Evaluate](#8_evaluate)

Ongoing evaluation must be a key element of your Open Access program. Once it has successfully launched, schedule time to review what worked and what did not work, and to document unexpected challenges. Review your original goals in light of your experience and refine them for the future.

Finally, do not keep that evaluation to yourself. The Open Access community embraces openness beyond collections. Sharing your lessons will help guide colleagues at other institutions, and may help you uncover new solutions. The solutions you developed can become best practices for others struggling with the same challenges.



# [9. Join The Community](#9_join_the_community)

Open Access for 3D collections is experiencing a formative moment. It has the benefit of building on the accumulated knowledge of 2D digitization and the broader Open Access community. A handful of leaders have begun to blaze a trail forward to help define what Open Access can mean for 3D cultural objects.

At the same time, technology and best practices are rapidly evolving. Today’s best practice will be surpassed by better techniques. Technology will become less expensive and easier to use. The community will grow. Embrace this inevitability by sharing practices and learning together.

All of these factors combine to create an opportunity to help define what it means to build a successful Open Access 3D program. What uses make sense? What files are best? Where should you look for partnerships? These are questions we are working together to answer.

This resource was created at a moment in late 2019 and early 2020 to help bring together the current best answers to those questions. We hope it will be useful to you and the larger community, and that you will help evolve it with us.


# [Appendix](#appendix)



# [i. Leading Examples of 3D Models and Open Access](#leading_examples_of_3d_models_and_open_access)

    The following organizations are leading examples of 3D models and Open Access of cultural resources.




##    [i.i. The Cleveland Museum of Art (CMA)](#the_cleveland_museum_of_art)


The Cleveland Museum of Art went Open Access in January 2020[^61] with the Open Access release of data and 2D images. Its policy also enables others to create their own 3D scans of public domain collections at the institution within certain conditions.[^62] CMA subsequently scanned and made available 3D images in partnership with Sketchfab on its platform and via the museum’s website using the Creative Commons Zero Public Domain Dedication for cultural resource items in the public domain.[^63] CMA was one of the first museums to make 3D models available on a museum website and use the Creative Commons Zero Public Domain Dedication. CMA plans to continue its 3D digitization efforts in years to come to present more interactive experiences for users and to innovate the production of cultural resources.



##    [i.ii. The National Gallery of Denmark (Statens Museum for Kunst; SMK)](#smk)
The National Gallery of Denmark (SMK) has been a pivotal leader in the international Open Access movement since 2016. Lead by Senior Advisor and Curator of Digital Museum Practice Merete Sanderhoff, with Head of Digital Jonas Heide Smith, the [SMK Open](https://www.smk.dk/en/article/smk-open/) program has produced important philosophical position statements through its blog, co-sponsored the “Sharing Is Caring” conference series[^64] that introduced innovative prototypes and new products, and continued to progress consistently with its ongoing rigorous commitment to Open Access. SMK has made significant contributions to the 3D imaging space as well, with its digital cast collection[^65] and partnerships with initiatives like Scan the World[^66] and MyMiniFactory.[^67] SMK partners with Sketchfab[^68] also to provide access to 3D images. 3D models of sculpture were also made available to explore on mobile devices in augmented reality.[^69]

The ethos of SMK’s efforts with Open Access and its 3D images are defined by “radical openness” and it views cultural resource items as building blocks for making new culture:


>SMK breaks away from the idea that museums should create all content themselves. SMK Open provides access to art, essentially offering it up as building blocks. Then you can put these blocks together to create brilliant content, play around with art and come up with great ideas.

>The museum hopes that setting the art free will pave the way for many more excellent user experiences—and for art becoming relevant to many more people.[^70]

SMK’s [project blog post](https://medium.com/smk-open/ghost-in-the-scan-3d-scans-of-casts-in-the-smks-collections-79560f895369) by Magnus Kaslov on 3D scanning speaks to the philosophical imperative of cultural resource items having expressive life, although it references these in different terms, such as “ghosts,” “aura,” “power,” and “spiritual meaning”:


>To return to the quote presented in my introduction, it should be noted that Digital Casts offers a new perspective of one of the key subjects of art and art history: the power of attraction that images exert. The fact that reproductions almost magically retain some of the aura—or ghost, or value, or meaning, or whatever you wish to call it—of what they represent. What the art historian David Freedberg calls “the power of images” in his by now classic book bearing the same title.


>Images speak to us, and we want to speak to them. This also holds true of three-dimensional images. We like to surround ourselves with them and to possess them. 3D scans retain some of the traits that fascinate us about the original sculptures. I cannot say exactly what that is, but something very clearly lingers. This trait is not only useful for those who present art—it also adds poignancy to the subsequent existence of these 3D models as they are put to various uses. . . .


>He [Julius Lange, First Director of The Danish Royal Cast Collection] didn't contest that the originals also had their merits which he called sentimental value, the same as the relic had ahead of the cast, but that did not bear on the artistic value. Marble and bronze were beautiful materials, yet the plaster in full reproduced the plastic shape: “from where the work of art gets its spiritual meaning.”[^71]


##    [i.iii. The Smithsonian Institution](#smithsonian_institution)

The 3D Program team, within the Smithsonian Digitization Program Office, has built a corpus of 3D models of cultural resource items across the breadth and depth of the Smithsonian with examples from art, natural history, science and technology, and more.[^72] It has been working on developing a 3D model program since 2010,[^73] and in 2013 it hosted the notable _Smithsonian X 3D_ Conference.[^74] The Smithsonian 3D initiative has contributed to technological development with its open-source 3D viewer and authoring tool suite, Voyager.[^75] An especially important resource is Smithsonian 3D Metadata Model,[^76] which furthers the identification of essential data elements in an effort to support greater standardization and interoperability in the field. Regular publishing about the 3D initiative in _Smithsonian_ magazine, Digitization Program Office blog, and other media outlets have provided important updates to educators, enthusiasts, and peer practitioners at other cultural institutions.

In partnership with companies such as Autodesk,[^77] Google,[^78] Amazon,[^79] and others, the 3D program serves as an important digital educational resource for learning in and outside the classroom with augmented reality, mobile, and web browser technologies. The Smithsonian links its 3D imaging digitization practice with the history of cultural resource items reproduction.[^80] 3D models have been used at the Smithsonian to help tell stories of new institutions, like the National Museum of African American History and Culture,[^81] and commemorate milestones in human achievement with Neil Armstrong’s spacesuit.[^82]

On February 25, 2020, the Smithsonian took an important step to include 3D models as part of its Open Access program.[^83] As part of the Open Access launch, the Smithsonian made available its 3D data with the glTF™ open standard developed by The Khronos Group[^84] and provided CC0 designated models to Sketchfab.[^85] As the Smithsonian continues to digitize and make available its 3D cultural resource items with more openness, it may better support the potential identified by William Tompkins, national collections coordinator at the Smithsonian Institution, who said, “The beauty of this technology is that it does basically put museums together internationally into one global environment.”[^86]



# [ii. Anatomy of a 3D Model](#anatomy_of_a_model)

##    [ii.i. Shape](#shape)

A 3D model primarily differs from a 2D image by the addition of an extra dimension. Pixels in a digital 2D image exist on an X and Y axis (left and right, up and down), pixels in a 3D model can exist on these planes but also the Z axis, (forward and backward/closer and farther away from the viewer).



<p id="gdcalert28" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text27.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert29">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![2D perspective compared to 3D perspective](images/2dvs3d.png "2D perspective compared to 3D perspective")

###### Illustration of the difference between a 2D image and 3D model, [https://help.sketchfab.com/hc/en-us/articles/360017787651-Learning-3D-Part-I-Simple-geometry](https://help.sketchfab.com/hc/en-us/articles/360017787651-Learning-3D-Part-I-Simple-geometry).

Knowing that we have three axes of movement, we can place a point in 3D space that exists somewhere along each plane of movement. With regard to 3D, we generally call this point a **vertex**. A 3D model composed exclusively of **vertices** is known as a **point cloud**.

<div class="sketchfab-embed-wrapper">
    <iframe title="A 3D model" width="640" height="480" src="https://sketchfab.com/models/3d531d9bb4dc479ca66e30136cf89229/embed?preload=1&amp;ui_controls=1&amp;ui_infos=1&amp;ui_inspector=1&amp;ui_stop=1&amp;ui_watermark=1&amp;ui_watermark_link=1" frameborder="0" allow="autoplay; fullscreen; vr" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/3d-models/st-alfege-church-greenwich-3d531d9bb4dc479ca66e30136cf89229?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">St Alfege Church Greenwich</a>
        by <a href="https://sketchfab.com/GreenwichVistaLand?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">GreenwichVistaLand</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
</div>

(_target_)

###### Point cloud of St. Alfege Church

If we join two **vertices** in different 3D positions with a line, we create an **edge**.

![An edge](images/edge.gif "an edge")


Joining three vertices, we are able to create the simplest 3D surface: a **triangle**.

![A triangle](images/triangle.gif "a triangle")


A triangle has a front and a back surface, with the angle direction of the front surface being named the **normal**. A 3D surface made of four joined vertices is called a **quad**.

![A quad](images/quad.gif "a quad")


Any surface created by joining five or more vertices is called a **polygon**, or **ngon** for short.

![An ngon](images/ngon.gif "an ngon")

Triangles, quads, and ngons are collectively referred to as **faces**.

By joining and aligning 3D faces, we are able to begin describing 3D shapes from simple pyramids and cubes, all the way up to complex forms like statues, vases, skulls, entire buildings, land masses, etc. These joined up faces are referred to as the **mesh**, **geometry**, or **surface** of a 3D model.

Example: [AT 237 Harpoceras falciferum (Fossil ammonite)](https://sketchfab.com/models/004a3d0dea654f89a9814cd65053b449) by [3D Fossils GB](https://sketchfab.com/3dFossils).

As a general rule, the more vertices, edges, and faces used to describe a given cultural resource, the more accurately that form will be described in digital 3D. This is often referred to as the **resolution** or **fidelity** of a 3D model. As the resolution of a 3D model increases, so too does the file size and the computational power required to create, capture, and display it in real-time 3D.

<div class="sketchfab-embed-wrapper">
    <iframe title="A 3D model" width="640" height="480" src="https://sketchfab.com/models/8c65ab68b4ec4bd5a2bdc9f8f072023a/embed?preload=1&amp;ui_controls=0&amp;ui_infos=0&amp;ui_inspector=0&amp;ui_stop=0&amp;ui_watermark=0&amp;ui_watermark_link=0" frameborder="0" allow="autoplay; fullscreen; vr" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/3d-models/surface-mesh-resolution-comparison-8c65ab68b4ec4bd5a2bdc9f8f072023a?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Surface Mesh Resolution Comparison</a>
        by <a href="https://sketchfab.com/nebulousflynn?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Thomas Flynn</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
</div>

(_target_)

Deciding the output resolution for your 3D model should take into account the intended audience and destination for the data.



##    [ii.ii. Color](#color)

In addition to describing a shape or form in 3D, a mesh can have (among other things) color information attached to or embedded within it. There are a number of techniques that can be used to add color to a 3D model. They vary based on the original source of the color information, how the color information is attached to specific points on the shape, and how the integrity of the color changes as the model is scaled.



###        [ii.ii.i. Vertex Color](#vertex_color)

One way to color a 3D mesh is to assign a color value to each individual vertex. The color of any connected edge or face is then calculated on a gradient between the joined vertices. This is known as **vertex coloring**, and a mesh colored in this way is said to be **vertex colored**. The surface color of a vertex colored mesh is therefore directly linked to the fidelity of the mesh—if you reduce the resolution of the mesh, you reduce the resolution of the surface color information.

<div class="sketchfab-embed-wrapper">
    <iframe title="A 3D model" width="640" height="480" src="https://sketchfab.com/models/fdb7cf90407e49f49159aab85e2b7971/embed?preload=1&amp;ui_controls=0&amp;ui_infos=0&amp;ui_inspector=0&amp;ui_stop=0&amp;ui_watermark=0&amp;ui_watermark_link=0" frameborder="0" allow="autoplay; fullscreen; vr" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/3d-models/bust-of-herakles-vertex-colour-only-fdb7cf90407e49f49159aab85e2b7971?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Bust of Herakles - Vertex Colour Only</a>
        by <a href="https://sketchfab.com/nebulousflynn?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Thomas Flynn</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campaign=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
</div>

(_target_)



###        [ii.ii.ii. UV Texture Maps](#uv_texture_maps)

In addition to coloring a 3D face using a blended gradient, it is possible to assign part of a 2D image file to fill the polygon or triangle surface. The method of assigning parts of an image to a 3D mesh surface is called **UV mapping**. This allows you to create the shape of the object in 3D and then apply a 2D image of the object to give it color and visual texture.

Because the X, Y, and Z axes are already used to describe the 3D geometry, the letters U and V are used to describe horizontal and vertical axes of a 2D image.

To align the 3D surface with the 2D image, certain edges on the mesh are designated **seams** where faces can be split apart and so flattened and arranged against the image. While this may sound complicated, most 3D capture and creation software calculate UV maps automatically.

A simple analogy for a UV map is flattening the six sides of a 3D cube:

![Flattened cube image](images/flat_cube.png "flattened cube")


###### [Cube UV Map Demo](https://sketchfab.com/models/4627658087f3482f8a2732c722e2bfeb) by [Thomas Flynn](https://sketchfab.com/nebulousflynn), viewed with [Sketchfab’s Model Inspector](https://help.sketchfab.com/hc/en-us/articles/115004862686-Model-Inspector) to show the UV mapped image next to the 3D model. The red dot indicates a shared position across both 3D and 2D spaces.

Image maps for 3D models are saved in a 1:1 format and in pixel sizes that are “powers of two”—that is, 128x128 pixels, 512x512 pixels, 1024x1024 pixels, etc. As you might expect, the larger the UV image map dimensions, the higher the number of pixels are assigned to a given 3D face, and the visual resolution is increased. This in turn increases the 3D model’s overall file size and the computational processing power required to render it.

Deciding the output resolution for your UV maps should take into account the intended audience and destination for the data.


Unlike vertex coloring, UV mapping allows a 3D mesh to be colored independently of the mesh’s resolution. This means that a high-resolution 3D mesh can be simplified or **decimated**—that is to say a given cultural resource can be represented by a mesh with a fewer number of vertices, edges, and faces, while maintaining color fidelity.

Vertex coloring and UV mapping are not mutually exclusive, and the same 3D mesh can include vertex colors and UV-mapped colors which, depending on the 3D renderer, can be combined for the final visual output.



        3. Normal and Roughness Map—Specialized UV maps

In addition to coloring the faces of a 3D mesh, there are several other texture maps[^87] that can have a dramatic effect on the presentation of a 3D model. Two baseline recommended map types are described below, but there are many more that can be created and applied to a 3D model to help more accurately render a given cultural resource.





            1. Normal Maps

Each face of a 3D model has a surface direction, known as a _normal_. This direction dictates how simulated light bounces off the surface. If we have simplified or decimated a 3D model significantly during optimization, we can run into the problem that a single face replaces much more complex geometry.

A common remedy for this is to encode complicated surface information from a high-resolution version of our model into a special texture map called a **normal map **and then map that to the lower-resolution mesh.



<p id="gdcalert35" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text34.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert36">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text34.png "image_tooltip")


3D model [Quarter Normal Map RTI](https://sketchfab.com/models/b7ea8c18fba84041a3259013703aeb32) by [Kevin Falcetano](https://sketchfab.com/falce003) rendered without a normal map...



<p id="gdcalert36" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text35.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert37">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text35.png "image_tooltip")


...and with a normal map. This model is composed of a single quad face.



            2. Roughness Maps

Any given cultural resource may include several different surface finishes or be made of several different materials, perhaps with significant differences in how rough or shiny they are. It is not currently possible to easily capture such variation during digitization.

It is possible as part of the post-processing of a 3D model, however, to author a special texture map called a **roughness map** that can be applied to a 3D model’s UV-mapped surface and show different areas of the surface as having different specular properties. A roughness map is a grayscale image which, depending on the 3D viewer being used, will show darker areas as rough and lighter areas as smooth or vice versa.[^88]



<p id="gdcalert37" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text36.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert38">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text36.png "image_tooltip")
3D model ‘[Chrysanthemums by a Stream,’ byōbu](https://sketchfab.com/models/cbbc0ab5634946d3bfc949c0aff685e6) by Thomas Flynn rendered without a roughness map or simulated lighting... \




<p id="gdcalert38" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text37.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert39">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text37.png "image_tooltip")


...the model with a roughness map and lighting applied. Note the reflective highlight now apparent in the areas of gold leaf. The effect is even more apparent when viewed in 3D.



3. Common Types of 3D Model

While there are as many types of 3D files as there are applications for 3D, we will now look at types of 3D models most common to cultural heritage applications. Note that we are not talking about _file formats _just yet, simply the general groups of 3D files you can expect to come across in the wild.



    6. Mesh + UV Texture Maps

Several 3D file formats support a 3D mesh in conjunction with a linked or embedded image map. Image files either need to be stored alongside the 3D mesh or are embedded in the 3D file itself.



<p id="gdcalert39" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text38.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert40">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text38.png "image_tooltip")




    7. Untextured Mesh

A 3D mesh without any color data applied is said to be **untextured**. Untextured meshes are useful in situations in which the color information related to a cultural resource is not of use—for example, in certain methods of 3D printing or when the 3D form itself is what is important. Some 3D capture techniques like **X-ray computed tomography (CT scanning)** or some **structured light **scanning will not capture color data at the time of digitization.



<p id="gdcalert40" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text39.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert41">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text39.png "image_tooltip")




    8. Vertex Colored Mesh

The description of this coloring method is covered above, and it is a common output of some types of 3D scanning processes. Typically, any process that involves the capture or computation of colored vertices as part of 3D data production can lead to a vertex colored mesh output.



<p id="gdcalert41" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text40.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert42">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text40.png "image_tooltip")




    9. Point Cloud

A point cloud or pointcloud is exactly what it sounds like: a 3D model made up exclusively of vertices (points). These kinds of files are commonly an output of LiDAR scanners (often referred to as _laser scanners_) or photogrammetry software. The vertices in a point cloud can be uncolored or have a color value assigned to them.



<p id="gdcalert42" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text41.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert43">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text41.png "image_tooltip")




    10. Volumetric Data

Volumetric data is less common than surface model data in cultural heritage applications, and it is possible to generate a surface model from a volumetric input using specialized software.

**X-ray computed tomography **is a scanning technique that is capable of documenting the visible form of a cultural resource, as well as internal structures not visible to the human eye. This technique generates numerous cross-sectionals through a subject using multidirectional x-ray measurements.

The cross-sectional images can be used to generate **volumetric 3D data**—that is, data that visualizes densities of volume.



<p id="gdcalert43" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text42.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert44">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text42.png "image_tooltip")


Volumetric render of a Gorilla Cranium derived from DICOM files in [aleph-viewer.com](https://aleph-viewer.com/).



    11. Additional features
        4. Animation

3D models can be animated in several ways. While animating models is beyond the scope of this paper, animation can help better describe how a cultural resource is constructed, functioned, or was used. Animation could also be the only way to record certain cultural performances, such as dance or theatre.



<p id="gdcalert44" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text43.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert45">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text43.png "image_tooltip")


Still from the animated 3D model [Columbian Press No 3180](https://sketchfab.com/models/b6bd7b136b1e46dda66c6068d6dbb927) by [Arboo](https://sketchfab.com/arboo).



        5. 3D Post-Production—Materials and Lighting

When we talk about “capturing a cultural resource in 3D,” we are most often referring to documenting the physical shape of the resource and possibly the surface color as well. Many cultural resources, however, are made from materials that possess specific physical properties that also contribute to a viewer’s understanding of the resource.

Consider the translucency of a fine marble statue, the colored transparency of a stained glass window, the difference in reflective properties between a wooden walking stick and its polished brass handle. These properties are as much a part of the resource’s nature as its simple shape and color.

At the time of writing, it is not practically possible to capture or record many of the physical traits that differentiate metals from ceramics, glass from paper, etc. during the 3D digitization process. Some of these physical properties can, however, be added by a 3D expert or artist during a post-production phase.[^89] \


Decisions should be made during the digitization process that will impact the ease with which these properties can be added. Therefore it is helpful—although not necessarily critical—to consider how you plan to treat these properties during the planning phase.

In the real world, understanding of the visible physical properties as described above rely in part upon interaction between viewer perspective and the object, but also on the lighting environment surrounding both. The same is true when viewing a digital 3D model of a cultural resource that is said to be **lit **or **shadeless**,** **depending on whether or not simulated lighting is present during the digital viewing experience.

Just as in a museum environment, lighting can make a huge difference to how a cultural resource is visually presented, which in turn has an effect on how an object is understood by a viewer.[^90] \




<p id="gdcalert45" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text44.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert46">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text44.png "image_tooltip")
Unlit version of [What is the genuine Nefertiti?](https://sketchfab.com/models/1295e14c5e634465aa2438004bb8886c) by [AD&D 4D, ES](https://sketchfab.com/add4d)...



<p id="gdcalert46" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text45.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert47">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text45.png "image_tooltip")
...the same 3D scene with a simulated lighting environment.



4. Common 3D Capture and 3D Creation Techniques and Software
    12. Capture

“Capture” refers to the process of recording an existing cultural resource via digitization process.



        6. Photogrammetry

As photography is a method for converting 3D information into a 2D format, photogrammetry does the opposite, converting 2D information back into digital 3D.

This workflow involves first capturing a number of images of a cultural resource from a number of different angles. This can be achieved by moving the camera around the resource itself or placing the resource upon a turntable in front of a static camera. A set of images intended for a photogrammetry workflow can number anywhere from a few dozen up to the many thousands.

You can use almost any kind of digital camera, but the better the images you capture, the better your output 3D model will be. \


Photogrammetry software is then able to process the digital image files (JPGs, RAW files) into a 3D model by comparing recognizable points in different images and calculating their position in 3D space using complex algorithms. The points (vertices) can then be used to define a 3D mesh and a color image map can be built from selected parts of the 2D image files.

In general, the more images that are input into and processed by photogrammetry software, the higher the output 3D model and textures will be. Using a higher number of images also requires more processing power or processing time to compute the output 3D model.

<span style="text-decoration:underline;">Requirements</span>

Digital camera, photogrammetry software, computer hardware (ideally with powerful, dedicated graphics hardware). Little specialist training, working knowledge of photography useful.

<span style="text-decoration:underline;">Entry-Level Equipment Budget</span>

Camera	$300+

Computer	$800+

Software	$0 (open source)

		$200+ (commercial)

<span style="text-decoration:underline;">Outputs</span>

Point clouds, surface meshes, vertex color information, UV image-mapped color information.

<span style="text-decoration:underline;">Applications</span>

Can capture objects of all sizes from miniature up to entire landscapes.

<span style="text-decoration:underline;">Limitations</span>

Difficult to capture subjects that are very shiny, transparent, extremely fine (e.g., hair, feathers). Subject scale must be added manually in software.

<span style="text-decoration:underline;">Commonly Used Software</span>[^91]

[3DF Zephyr](https://www.3dflow.net/3df-zephyr-pro-3d-models-from-photos/)

[Agisoft Metashape](https://www.agisoft.com/)

[Autodesk ReCap](https://www.autodesk.com/products/recap/overview)

[Meshroom](https://alicevision.org/#meshroom)

[RealityCapture](https://www.capturingreality.com/)



        7. Structured Light

Structured light 3D scanners use specially calibrated projectors and cameras simultaneously projecting and recording a known pattern of lines or grids onto the subject being scanned. Dedicated software then defines a 3D surface model, based upon the distortions in the recorded line or grid pattern made by the subject.

Structured light scanners often exist as dedicated hardware or as a combination of conventional consumer level projectors and cameras. Dedicated hardware systems benefit from known levels of capture accuracy. Some capture scenarios also involve using additional scanning targets.

<span style="text-decoration:underline;">Requirements</span>

Dedicated structured light scanning hardware OR digital projector(s) and camera(s), structured light scanning software, computer hardware (ideally with powerful, dedicated graphics hardware). Little specialist training.

<span style="text-decoration:underline;">Estimated Entry-Level Equipment Budget</span>

Handheld Scanner	$5,000+

Computer		$800+

<span style="text-decoration:underline;">Outputs</span>

Surface meshes, vertex color information, UV image mapped color information, scale.

<span style="text-decoration:underline;">Applications</span>

Capturing small-to-medium-sized objects.

<span style="text-decoration:underline;">Limitations</span>

Attempting to scan very large objects generally results in the creation of unusable amounts of data. Color data capture is generally inferior to photogrammetry.

<span style="text-decoration:underline;">Commonly Used Structured Light Scanners</span>

[Artec](https://www.artec3d.com/)

[Creaform](https://www.creaform3d.com/en)

[HP DAVID](https://www8.hp.com/us/en/campaign/3Dscanner/overview.html)

[NextEngine](http://www.nextengine.com/)



        8. LiDAR / Laser Scanning

Laser scanning hardware is most often used in building information modeling (BIM) to record spaces and architectural scale features. Essentially, laser scanning works by firing a laser from a central unit and recording the 3D position of any surface it strikes, based upon how long the reflected light takes to return to the base station.

<span style="text-decoration:underline;">Requirements</span>

Laser scanning base station, computer hardware (ideally with powerful, dedicated graphics hardware). Some specialist training.

<span style="text-decoration:underline;">Estimated Entry-Level Equipment Budget</span>

LiDAR Scanning Unit	$5,000+

Computer			$800+

<span style="text-decoration:underline;">Outputs</span>

Color or monochrome point clouds, scale.

<span style="text-decoration:underline;">Applications</span>

Architecture and landscape scale subjects where accurate measurements are essential.

<span style="text-decoration:underline;">Limitations</span>

No surface or UV mapped color capture, generally not suitable for smaller objects.

<span style="text-decoration:underline;">Commonly Used Hardware</span>[^92]

[FARO](https://www.faro.com/)

[Leica](https://leica-geosystems.com/en-us/products/laser-scanners)

[RIEGL](http://www.riegl.com/)

[Trimble](https://geospatial.trimble.com/products-and-solutions/laser-scanning-solutions)



        9. X-ray Computed Tomography

Commonly used in medical and scientific fields.

<span style="text-decoration:underline;">Requirements</span>

Dedicated x-ray tomography machine, specialist training.

<span style="text-decoration:underline;">Entry-Level Equipment Budget</span>

X-ray CT Scanning Machine		$350,000 - million+

PC Computer				$2,000 - 10k+

<span style="text-decoration:underline;">Outputs</span>

Density, scale, 2D image sets from which 3D surface models can be derived.

<span style="text-decoration:underline;">Applications</span>

Very-small-to-medium-size objects, especially where measurements and internal structures are of interest.

<span style="text-decoration:underline;">Limitations</span>

No surface color information, scan size limited by x-ray machine volume/portability of subject.

<span style="text-decoration:underline;">Example X-Ray CT Setups \
[AN15 ES Flat Panel Detector](https://www.perkinelmer.com/PDFs/Downloads/XRD%20Series%20Product%20Note.pdf)</span>

[Nikon Metrology HMX ST 225](https://www.nikonmetrology.com/en-us/product/xt-h-225-st)

[YXLON Access Y.100 + 450kV, 0.4mm Focal Spot X-Ray Tube and PerkinElmer XRD 1621](https://www.yxlon.com/en/products/x-ray-and-ct-inspection-systems/yxlon-ff85-ct)

[ZEISS Versa](https://www.zeiss.com/microscopy/us/products/x-ray-microscopy/zeiss-xradia-610-and-620-versa.html)



        10. Motion Capture

As the name suggests, motion capture is a digitization technique for capturing movement, most often that of human beings (e.g., full body, facial, hand motion). Traditionally this technique has required studio spaces with specialized cameras and tracking targets attached to the human performers. More recent developments in depth-sensing cameras and even smartphones are making motion capture a much more accessible technology.

<span style="text-decoration:underline;">Entry-Level Equipment Budget</span>

$$ - $$$$$ Dedicated Setup

$-$$$ Rental

<span style="text-decoration:underline;">Requirements</span>

Motion capture studio or stage, bodysuits and targets, specialized cameras, computer hardware (ideally with powerful, dedicated graphics hardware). Specialist training.

OR

Depth-sensing camera, computer hardware (ideally with powerful, dedicated graphics hardware), some specialist training.

<span style="text-decoration:underline;">Outputs</span>

Motion capture data.

<span style="text-decoration:underline;">Applications</span>

Full body, facial, hand. and object motion recordings.

<span style="text-decoration:underline;">Limitations</span>

No 3D model capture.

<span style="text-decoration:underline;">Example Motion Capture Setups</span>

[digitalartsonline.co.uk/news/motion-graphics/how-do-3d-motion-capture-using-iphone-x-camera](https://www.digitalartsonline.co.uk/news/motion-graphics/how-do-3d-motion-capture-using-iphone-x-camera/)

[themocapstudio.co.uk](https://www.themocapstudio.co.uk/#)

[pisoft.com](http://ipisoft.com/)



    13. 3D Reconstruction and Creation

In addition to 3D scanning of a cultural resource, another way to generate 3D content is to engage a 3D artist to create it from scratch. This method is especially applicable to any cultural resource that is “unscannable,” no longer exists or was destroyed, or never existed in the first place—e.g., a fictional space or object.

Authoring—as opposed to capturing—3D models is an entirely different skill set to 3D scanning, and an expert 3D artist often will have studied their craft at a higher education level or have self taught their skills through years of practice.

Several sub-disciplines of creative work are applicable to generating 3D models for cultural heritage.



        11. Modeling

3D modeling is the process of creating a three-dimensional representation of a surface or object by manipulating faces/polygons, edges, and vertices in simulated 3D space. Just as Adobe Photoshop and MS Paint are software programs used to create 2D art, 3D modeling software allows users to make art that can be explored in three dimensions.

Typical subjects for a modeling workflow include inorganic structures, architecture, industrial subjects, houseware, furniture, and mechanical structures.

<span style="text-decoration:underline;">Commonly Used Software</span>

[3ds Max](https://www.autodesk.com/products/3ds-max/overview)

[Blender](https://www.blender.org/)

[Cinema 4D](https://www.maxon.net/en-us/products/cinema-4d/overview/)

[Maya](https://www.autodesk.com/products/maya/overview)

[SketchUp](https://www.sketchup.com/)



<p id="gdcalert47" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text46.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert48">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text46.png "image_tooltip")


[Bull Sand Fort, Humber Estuary, WW2](https://sketchfab.com/models/b731f4ef37f347b1adaf980d54b9d379) reconstruction by [Hannah Stamp (Rice)](https://sketchfab.com/hannahrice).



        12. Texture Painting

Once a 3D model has been created, an additional (sometimes essential) stage in production is to apply realistic colors and materials to the geometry. All texture maps (i.e., color, normal, roughness) can be digitally painted onto a 3D mesh, whether a 3D scan or something that has been created by a 3D artist.

Texture painting makes use of the UV mapping color method described previously and outputs an image file to be associated with a 3D model.

<span style="text-decoration:underline;">Commonly Used Software</span>

[3DCoat](https://3dcoat.com/)

[ArmorPaint](https://armorpaint.org/)

[Blender](https://www.blender.org/)

[Substance Painter](https://www.substance3d.com/products/substance-painter/)

[ZBrush](https://pixologic.com/)



<p id="gdcalert48" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text47.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert49">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text47.png "image_tooltip")


[South Cross, Castledermot—polychromatic](https://sketchfab.com/models/c9c9b1d74d6945c2980a5f0481433b97) by [John McCarthy](https://sketchfab.com/JohnMccarthy).



        13. Sculpting

As the name suggests, 3D sculpting is the process of manipulating a 3D object as if it was made out of a material similar to clay. You can push, pull, smooth, grab, pinch, and edit a 3D object to be whatever you’d like.

Typical subjects for a sculpting workflow include organic forms, animals, plants, insects, artistic sculptures, fabrics, and people.

<span style="text-decoration:underline;">Commonly Used Software</span>

[3DCoat](https://3dcoat.com/)

[Blender](https://www.blender.org/) \
[Mudbox](Mudbox)

[Meshmixer](http://www.meshmixer.com/)

[ZBrush](https://pixologic.com/)



<p id="gdcalert49" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text48.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert50">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text48.png "image_tooltip")


[Buddha Statue Hand Studies](https://sketchfab.com/models/28bbbcdc75d44f50aea6b57ab124ef6f) by [boonie4dee](https://sketchfab.com/booni4dee).



        14. Voxels

A creation popularized by the videogame _Minecraft_, voxel-based 3D modeling uses visible 3D cubes or blocks (voxels) to build a 3D form. Voxel-based creations can be built “block by block” or existing meshes can be converted to a voxel form using a 3D editor. By no means useful for scientific study or hyper-realistic reconstructions, voxel-based 3D models can still be used to engage with wide-ranging audiences, especially younger crowds.[^93]

A voxel workflow can be used to create 3D representations of most subjects. but the output is generally highly stylized as a result of the nature of this creative technique.

<span style="text-decoration:underline;">Commonly Used Software</span>

[MagicaVoxel](https://ephtracy.github.io/)

[Minecraft](https://www.minecraft.net/en-us/community)

[Qubicle](https://www.minddesk.com/)

[WorldEdit](https://www.curseforge.com/minecraft/mc-mods/worldedit)



<p id="gdcalert50" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Lock-Text49.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert51">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>


![alt_text](images/Lock-Text49.png "image_tooltip")


[Digital Kids: Imagine, Build and Reveal, #1](https://sketchfab.com/models/2b9a66a39c464df2b4bfc64fc1ba64e7) by [V&A Digital Classroom](https://sketchfab.com/vandadigitalclassroom).



5. Quick Start 3D Digitization Guide

As a word of warning, be careful when using this “let’s just go ahead and capture some 3D and publish it” approach—you may unwittingly be laying a potentially unstable foundation for your organization’s 3D digitization program. Be mindful of how you share your project with your colleagues and in public as people new to the concept will often derive their opinion of 3D digitization and its potential benefits and shortcomings based upon your work.

You should also be aware that any time spent on a project will inevitably generate some form of technical and skill “debt”—i.e., commitment to processes and workflows based on the fact that they exist and are seen as the easiest option. This could make it difficult to change and adapt digitization workflows as required once proper planning is undertaken.



    14.
3D Capture Workflow
The cheapest and most accessible 3D capture workflow available to you is most likely photogrammetry. The input data are digital images and the required software runs on most computer hardware, with the caveat that on older and less powerful hardware, you will likely have to wait a lot longer for a 3D output to be processed. It is recognized that this suggested technology chain may still be unaffordable to some organizations.



        15. Camera

Your personal digital camera or smartphone camera are likely good enough for a test project.

Tested.com hosts a good “[photography for photogrammetry” guide](https://www.tested.com/art/makers/460142-art-photogrammetry-how-take-your-photos/).



        16. Software

Here’s a list of free photogrammetry software, with system requirements and official tutorials for each option. It is highly recommended that you review and consider the potential ongoing costs of using commercial software.


    [Meshroom]( https://alicevision.org/#meshroom)


    Open source, Win/Linux. By far the most user-friendly open source photogrammetry software.



*   [System Requirements](https://meshroom-manual.readthedocs.io/en/latest/install/requirements/requirements.html)
*   [Official Tutorial](https://sketchfab.com/blogs/community/tutorial-meshroom-for-beginners)

    [3DF Zephyr](https://www.3dflow.net/3df-zephyr-free/)


    Commercial, free version limited to 50 images, Win. The only non-time-limited free commercial software listed here.

*   [System Requirements](https://www.3dflow.net/zephyr-doc/en/SystemRequirements.html)
*   [Official Tutorials](https://www.3dflow.net/technology/documents/3df-zephyr-tutorials/)

    [Metashape](https://www.agisoft.com/downloads/request-trial/)


    Commercial, free trial, Win/Mac/Linux. One of the most commonly used photogrammetry software, 30-day time limited trial.

*   [System Requirements](https://www.agisoft.com/downloads/system-requirements/)
*   [Official Tutorials](https://www.agisoft.com/support/tutorials/beginner-level/)

    [Autodesk ReCap](https://www.autodesk.co.uk/products/recap/free-trial)


    Commercial, free trial, Win only, cloud-based processing.

*   [System Requirements](https://www.autodesk.co.uk/products/recap/free-trial#system-requirements)
*   [Official Tutorials](https://knowledge.autodesk.com/support/recap/learn?sort=score)
        17. Computer Hardware

Initially it is suggested that you simply try running one or all of the suggested software applications on your existing computer hardware. If you find that installing the software does not work or processing takes too long or frequently fails, then it might be time to consider investing in something new, basing your purchase on the system requirements in the software section.



        18. Publishing

See the Choosing an Online 3D Viewer section for hosted and self-hosted options.


<!-- Footnotes themselves at the bottom. -->
## Notes

[^1]:
     _See e.g._, NeuroDigital Technologies, _Touching Masterpieces_, [https://touchingmasterpieces.com/](https://touchingmasterpieces.com/), last accessed April 14, 2020.

[^2]:
     The Europeana Network Association’s _3D Content in Europeana Task Force_ report provides a wealth of information about current practices by European cultural institutions and suggestions for future standardization and harmonization. _3D Content in Europeana Task Force_, Europeana Pro (January 28, 2019), [https://pro.europeana.eu/project/3d-content-in-europeana](https://pro.europeana.eu/project/3d-content-in-europeana)

[^3]:
     The London Charter, see [http://www.londoncharter.org/](http://www.londoncharter.org/) and ReACH Technical Appendix, see [https://www.researchgate.net/publication/326776418_Technical_Appendix_ReACH_Declaration](https://www.researchgate.net/publication/326776418_Technical_Appendix_ReACH_Declaration) provide additional information about digitizing cultural objects.

[^4]:
     Within the Creative Commons framework, a Creative Commons Attribution license is the most restrictive license that qualifies. However, even that license should be used only if the institution actually holds a copyright in the cultural resource or digitized file. In the absence of a copyright (which will be absent in many cases discussed here), a CC0 Public Domain Dedication should be used.

[^5]:
     Jason Bailey and Neal Stimler, _Solving Art’s Data Problem—Part One, Museums_, Artnome (April 29, 2019), [https://www.artnome.com/news/2019/4/29/solving-arts-data-problem-part-one-museums](https://www.artnome.com/news/2019/4/29/solving-arts-data-problem-part-one-museums) Other important definitions about Open Access are in the 2003 Berlin Declaration, see _Berlin Declaration on Open Access to Knowledge in the Sciences and Humanities_, Max-Planck-Gesellschaft [https://openaccess.mpg.de/Berlin-Declaration](https://openaccess.mpg.de/Berlin-Declaration), last accessed April 16, 2020; the definition provided by Peter Suber in his book _Open Access_, see Peter Suber, _Open Access_ (2012), [https://mitpress.mit.edu/books/open-access](https://mitpress.mit.edu/books/open-access); and the definition maintained by Creative Commons, see _Open Access_, Creative Commons, [https://creativecommons.org/about/program-areas/open-access/, last accessed April 16, 2020.](https://creativecommons.org/about/program-areas/open-access/)

[^6]:
     International DOI Foundation, _Driven by DOI_, [https://www.doi.org/driven_by_doi/DOI_Marketing_Brochure.pdf](https://www.doi.org/driven_by_doi/DOI_Marketing_Brochure.pdf), last updated November 21, 2014. For example, the British Museum uses DOIs to track the data and models associated with the Rosetta Stone. _See_ _Data for the creation of the Rosetta Stone in 3D_, GitHub,  [https://github.com/portableant/rosettastone](https://github.com/portableant/rosettastone), last accessed April 16, 2020.

[^7]:
     _See e.g._, National Park Service, _NPS-28: Cultural Resource Management Guideline_,  [https://www.nps.gov/parkhistory/online_books/nps28/28contents.htm](https://www.nps.gov/parkhistory/online_books/nps28/28contents.htm/), last updated August 16, 2002. It is also important to consider how Open Access policies might interact with existing concepts of heritage, community autonomy, and cultural sovereignty. As much as possible, Open Access should be a practice that empowers individuals and groups with parity of opportunity, while upholding the principles of liberty, like freedom of conscience and expression.

[^8]:
     William Griswold, _Introducing Open Access at the CMA: For the Benefit of All the People Forever_,  Medium (January 23, 2019), [https://medium.com/cma-thinker/introducing-open-access-at-the-cma-for-the-benefit-of-all-the-people-forever-d3cd81964616](https://medium.com/cma-thinker/introducing-open-access-at-the-cma-for-the-benefit-of-all-the-people-forever-d3cd81964616)

[^9]:

     For a review of many institutions’ experiences with Open Access, see Effie Kapsalis, _The Impact of Open Access on Galleries, Libraries, Museums, & Archives_, Smithsonian Emerging Leaders Development Program (April 27, 2016), [http://siarchives.si.edu/sites/default/files/pdfs/2016_03_10_OpenCollections_Public.pdf](http://siarchives.si.edu/sites/default/files/pdfs/2016_03_10_OpenCollections_Public.pdf).

[^10]:
     Jane Park, _CC Search Is out of Beta with 300M Images and Easier Attribution_, Creative Commons Blog (April 30, 2019), [https://creativecommons.org/2019/04/30/cc-search-images/](https://creativecommons.org/2019/04/30/cc-search-images/)

[^11]:
     _Category Details for Images from Metropolitan Museum of Art_, Wikimedia, [https://tools.wmflabs.org/glamtools/baglama2/#gid=290&month=201911,](https://tools.wmflabs.org/glamtools/baglama2/#gid=290&month=201911) last accessed April 16, 2020.

[^12]:
    _ Category Details for Images from Cleveland Museum of Art_, Wikimedia, [https://tools.wmflabs.org/glamtools/baglama2/#gid=341&month=201908,](https://tools.wmflabs.org/glamtools/baglama2/#gid=341&month=201908) last accessed April 16, 2020.

[^13]:
     _Category Details for Rijksmuseum Amsterdam_, Wikimedia, [https://tools.wmflabs.org/glamtools/baglama2/#gid=113&month=202003,](https://tools.wmflabs.org/glamtools/baglama2/#gid=113&month=202003) last accessed April 16, 2020.

[^14]:
     Douglas McCarthy, _Open Access Arrives at the Cleveland Museum of Art_, Europeana Pro (January 23, 2019), [https://pro.europeana.eu/post/open-access-arrives-at-the-cleveland-museum-of-art](https://pro.europeana.eu/post/open-access-arrives-at-the-cleveland-museum-of-art) _See also_ Simon Tanner, _Reproduction Charging Models & Rights Policy for Digital Images in American Art Museums:_ _A Mellon Foundation Study_, King’s Digital Consultancy Services (August 2004), [http://www.kdcs.kcl.ac.uk/fileadmin/documents/pubs/USMuseum_SimonTanner.pdf](http://www.kdcs.kcl.ac.uk/fileadmin/documents/pubs/USMuseum_SimonTanner.pdf)

[^15]:
     The transition to Open Access may require a long-term effort to renegotiate and restructure third-party agreements that include limitations on Open Access. One of the first steps that many institutions can take to prepare for Open Access is to ensure new agreements do not include restrictions that would prevent the successful launch of an Open Access regime in the future.

[^16]:
     Microsoft In Culture, _Le Mont Saint-Michel at MOHAI Seattle_, [https://www.microsoft.com/inculture/arts/le-mont-saint-michel-mixed-reality/,](https://www.microsoft.com/inculture/arts/le-mont-saint-michel-mixed-reality/) last accessed April 16, 2020.

[^17]:
     ERA Media, _The Myth of Control, Incentive Alignment and How Openness Levels the Playing Field with Jonathan Bryce with Amber Cazzell and Jonathan Bryce_, Cazzell Report (February 26, 2020), [https://youtu.be/02xZF2EeRC4](https://youtu.be/02xZF2EeRC4)

[^18]:
     Amber Cazzell, _What Post Scarcity Means: Why the Post-Scarcity Economy Is Hard to Reason About_, Hackernoon (June 13, 2019), [https://hackernoon.com/what-post-scarcity-means-7c4d653418f4](https://hackernoon.com/what-post-scarcity-means-7c4d653418f4)

[^19]:
     Matt Wisdom, _3D Will Make Retailers a Lot of Money (If They Can Solve These 3 Problems)_, VentureBeat (October 23, 2019), [https://venturebeat.com/2019/10/23/3d-will-make-retailers-a-lot-of-money-if-they-can-solve-these-3-problems/](https://venturebeat.com/2019/10/23/3d-will-make-retailers-a-lot-of-money-if-they-can-solve-these-3-problems/)

[^20]:
     Stuart Jeffrey, _Digital heritage objects, authorship, ownership and engagement_,_ in _Authenticity and Cultural Heritage in the Age of 3D Digital Reproductions (ed. Paola Di Giuseppantonio Di Franco et al. 2018) 49-59, [https://www.academia.edu/37391064/Authenticity_and_cultural_heritage_in_the_age_of_3D_digital_reproductions](https://www.academia.edu/37391064/Authenticity_and_cultural_heritage_in_the_age_of_3D_digital_reproductions)

[^21]:
     Denis Sutton, _Authenticity in Art_, _in_ The Oxford Handbook of Aesthetics_ _Vol. 1. (ed. Jerrold Levinson, 2009) 1-17 [https://doi.org/10.1093/oxfordhb/9780199279456.001.0001](https://doi.org/10.1093/oxfordhb/9780199279456.001.0001)

[^22]:
     _See_ William Ivins, Prints and Visual Communication (1953) 3, [https://archive.org/details/printsandvisualc009941mbp](https://archive.org/details/printsandvisualc009941mbp)

[^23]:
     Bill Ivey, _Arts, Inc. How Greed and Neglect Have Destroyed Our Cultural Rights_ (2008) 23, [https://www.ucpress.edu/book/9780520267923/arts-inc](https://www.ucpress.edu/book/9780520267923/arts-inc)

[^24]:
     Bill Ivey, _Expressive Life_, Global Cultural Strategies (February 2016), [http://globalculturalstrategies.com/writings/expressive-life/](http://globalculturalstrategies.com/writings/expressive-life/)

[^25]:
     Dragan Espenschied and Klaus Rechert, _207.1 Fencing Apparently Infinite Objects_, 1 Rhizome (September 21, 2018), [https://doi.org/10.17605/OSF.IO/6F2NM](https://doi.org/10.17605/OSF.IO/6F2NM)

[^26]:
     _See_ Harry Verwayen et al., _The Problem of the Yellow Milkmaid: A Business Model Perspective on Open Metadata_, Europeana Pro (November 2011), [https://pro.europeana.eu/files/Europeana_Professional/Publications/Whitepaper_2-The_Yellow_Milkmaid.pdf](https://pro.europeana.eu/files/Europeana_Professional/Publications/Whitepaper_2-The_Yellow_Milkmaid.pdf)

[^27]:
     Paola Di Giuseppantonio Di Franco et al., _Introduction: Why Authenticity Still Matters Today, in_ Authenticity and Cultural Heritage in the Age of 3D Digital Reproductions (2018) 2, [https://www.academia.edu/37391064/Authenticity_and_cultural_heritage_in_the_age_of_3D_digital_reproductions](https://www.academia.edu/37391064/Authenticity_and_cultural_heritage_in_the_age_of_3D_digital_reproductions)

[^28]:
     _See e.g._, Alban Denoyel, _3D is the Backbone of Any Immersive Strategy_, Sketchfab Customer Stories (March 26, 2019), [https://sketchfab.com/blogs/enterprise/news/3d-strategy/3d-immersive-technology](https://sketchfab.com/blogs/enterprise/news/3d-strategy/3d-immersive-technology)

[^29]:
     _See_ Thomas Flynn, _Collections: 2D to 3D_, Sketchfab,  [https://sketchfab.com/nebulousflynn/collections/2d-to-3d](https://sketchfab.com/nebulousflynn/collections/2d-to-3d), last accessed April 16, 2020.

[^30]:
     Museum of British Colonialism, _Emergency: An Exhibition on the Mau Mau Conflict and British Colonial Rule in 1950s Kenya_, 1, 13,  [https://static1.squarespace.com/static/591175bf1b10e32648746640/t/5e273aa7de776a57d97e2588/1579629236853/Emergency+Exhibition+Guide-compressed.pdf](https://static1.squarespace.com/static/591175bf1b10e32648746640/t/5e273aa7de776a57d97e2588/1579629236853/Emergency+Exhibition+Guide-compressed.pdf)

[^31]:
     Franscisco Garrido, _Chilean Heritage in 3D: A New Life for the Collections of the MNHN_, Sketchfab (November 21, 2018), [https://sketchfab.com/blogs/community/chilean-heritage-in-3d-a-new-life-for-the-collections-of-the-mnhn/](https://sketchfab.com/blogs/community/chilean-heritage-in-3d-a-new-life-for-the-collections-of-the-mnhn/)

[^32]:
     Marta Pilarska, _Scanning the Horizon: 3D Collections of the Scottish Maritime Museum_, Sketchfab (February 5, 2020), [https://sketchfab.com/blogs/community/scanning-the-horizon-3d-collections-of-the-scottish-maritime-museum/](https://sketchfab.com/blogs/community/scanning-the-horizon-3d-collections-of-the-scottish-maritime-museum/)

[^33]:
     Annette Thoma, _Konzerthaus Berlin: Cultural Participation Through Digitisation_, Sketchfab (September 20, 2018), [https://sketchfab.com/blogs/community/konzerthaus-berlin-cultural-participation-through-digitisation/](https://sketchfab.com/blogs/community/konzerthaus-berlin-cultural-participation-through-digitisation/)

[^34]:
     _See, e.g._, _Cultural Heritage_, Sketchfab, [https://sketchfab.com/blogs/community/category/community-story/cultural-heritage/](https://sketchfab.com/blogs/community/category/community-story/cultural-heritage/), last accessed April 16, 2020.

[^35]:
     _See_ _3D und Virtual Reality_, IANUS (November 22, 2016), [https://www.ianus-fdz.de/it-empfehlungen/3d](https://www.ianus-fdz.de/it-empfehlungen/3d); _see also_ Anas Alaoui M’Darhri et al., _Share - Publish - Store - Preserve. Methodologies, Tools and Challenges for 3D Use in Social Sciences and Humanities_, PARTHENOS (February 2019), [https://hal.archives-ouvertes.fr/hal-02155055/document](https://hal.archives-ouvertes.fr/hal-02155055/document); _see also_ _Guides to Good Practice_, Archeology Data Service, [https://guides.archaeologydataservice.ac.uk/g2gp/3d_3-2](https://guides.archaeologydataservice.ac.uk/g2gp/3d_3-2), last accessed April 16, 2020.

[^36]:
     These audiences may be new communities or existing communities that have historically been underserved. For example, 3D models can help create tactile objects (real and virtual) to help reach blind and low-vision members of the public who might not otherwise have a rich or meaningful experience in a predominantly visual environment.

[^37]:
     These investigations can serve a wide range of purposes, even within the context of a single object. One research team used a scan of Jackson Pollock’s Alchemy to assist with diagnosis, conservation, and interpretation, as well as with the creation of an interactive kiosk that allowed viewers to explore the geometry of the work and a 1:1 physical model to help the public interact with the work. _See_ Marco Callieri et al., _Alchemy in 3D: A Digitization for a Journey Through Matter_, Digital Heritage (2015), [http://vcg.isti.cnr.it/Publications/2015/CPPDPLS15/DH2015%20(Post)%20-%20Alchemy%20in%203D%20A%20Digitization%20for%20a%20Journey%20Through%20Matter.pdf](http://vcg.isti.cnr.it/Publications/2015/CPPDPLS15/DH2015%20(Post)%20-%20Alchemy%20in%203D%20A%20Digitization%20for%20a%20Journey%20Through%20Matter.pdf)

[^38]:
     _See e.g._, British Museum Schools, Twitter (October 11, 2016), [https://twitter.com/BM_Schools/status/785832150276988930](https://twitter.com/BM_Schools/status/785832150276988930)

[^39]:
     _See e.g._, _Virtual Tour of Great Shrine of Amaravati_, British Museum (March 11, 2018), [https://business.facebook.com/soluisgroup/posts/2346489868709732?__tn__=-R](https://business.facebook.com/soluisgroup/posts/2346489868709732?__tn__=-R)

[^40]:
     Daniel Pett and Andrew Shore, _A New Dimension in Home Shopping_, British Museum Blog (July 31, 2017), [https://blog.britishmuseum.org/a-new-dimension-in-home-shopping](https://blog.britishmuseum.org/a-new-dimension-in-home-shopping/)

[^41]:
     Derby Silk Mill, _Co-Producing A 3D Imaging Programme at Derby Museums_, Sketchfab (December 12, 2017), [https://sketchfab.com/blogs/community/co-producing-3d-imaging-programme-derby-museums/](https://sketchfab.com/blogs/community/co-producing-3d-imaging-programme-derby-museums/)

[^42]:
     Bart Veldhuizen, _MicroPasts: Crowdsourcing Cultural Heritage Research_, Sketchfab (February 11, 2015), [https://sketchfab.com/blogs/community/micropasts-crowdsourcing-cultural-heritage-research/](https://sketchfab.com/blogs/community/micropasts-crowdsourcing-cultural-heritage-research/)

[^43]:
     LAPID, _Using 3D to Recover Heritage Lost in a Fire_, Sketchfab (January 24, 2020),  [https://sketchfab.com/blogs/community/lapid-using-3d-to-recover-heritage-lost-in-a-fire/](https://sketchfab.com/blogs/community/lapid-using-3d-to-recover-heritage-lost-in-a-fire/); _see also_ _How Cultural Institutions Use Sketchfab_, Sketchfab, [https://sketchfab.com/museums](https://sketchfab.com/museums), last accessed April 16, 2020 (providing links to success stories from museums and cultural partners).

[^44]:
     Professor Sonia Katyal explores the relationship between some legal and non-legal factors in her article, _Technoheritage_. _See generally _Sonia K. Katyal, _Technoheritage_, 105 Calif. L. Rev. 1111 (2017).

[^45]:
     There are a host of other cultural considerations to be aware of in many digitization projects. _See, e.g._, Mathilde Pavis and Andrea Wallace, _Response to the 2018 Sarr-Savoy Report: Statement on Intellectual Property Rights and Open Access Relevant to the Digitization and Restitution of African Cultural Heritage and Associated Materials_, JIPITEC (March 25, 2019),
     [https://www.jipitec.eu/issues/jipitec-10-2-2019/4910](https://www.jipitec.eu/issues/jipitec-10-2-2019/4910)

[^46]:
     Although copyright law is the most significant legal constraint on digitization and re-use of works, it is not the only possible constraint. Specific countries may have additional restrictions such as moral rights and cultural property rules that may govern use. Work with your legal partners to identify and resolve any additional legal barriers specific to your collection before moving forward.

[^47]:
     This rule is not universal. For example, in Mexico the term of protection is 100 years after the death of the author.

[^48]:
     The Wikimedia Commons maintains a list of copyright rules by country. _Copyright Rules by Territory_, Wikimedia Commons, [https://commons.wikimedia.org/wiki/Commons:Copyright_rules_by_territory](https://commons.wikimedia.org/wiki/Commons:Copyright_rules_by_territory), last updated April 12, 2020. Europeana provides a calculator for some works in some EU countries.  _Button-Based Public Domain Calculator_, Europeana Connect, [https://archive.outofcopyright.eu/calculator.html](https://archive.outofcopyright.eu/calculator.html) (last accessed April 16, 2020) There are also many idiosyncrasies around specific works and countries._ See, e.g._, Katarzyna Strycharz, _Public Domain: Why it is not that simple in Europe_, Medium (January 26, 2016), [https://medium.com/copyright-untangled/public-domain-why-it-is-not-that-simple-in-europe-1a049ce81499](https://medium.com/copyright-untangled/public-domain-why-it-is-not-that-simple-in-europe-1a049ce81499) https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2145862

[^49]:
     _See generally_ Meshwerks, Inc. v. Toyota Motor Sales U.S.A., Inc., 528 F.3d 1258 (10th Cir. 2008), and Bridgeman Art Library, Ltd. v. Corel Corp., 36 F. Supp. 2d 191 (S.D.N.Y. 1999). For a more detailed analysis, see Michael Weinberg, _3D Scanning: A World Without Copyright_, Shapeways (May 2016), [https://www.shapeways.com/blog/wp-content/uploads/2016/05/white-paper-3d-scanning-world-without-copyright.pdf](https://www.shapeways.com/blog/wp-content/uploads/2016/05/white-paper-3d-scanning-world-without-copyright.pdf); _see also_ Paul Banwatt and Laura Robinson, _Dispatches from the Front Lines of 3D Copyright_, 28 Intell. Prop. J. 237 (2016).

[^50]:
     _See_ Thomas Margoni, _The Digitization of Cultural Heritage: Originality, Derivative Works and (non) Original Photographs_, Institute for Information Law (December 3, 2014), [https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2573104](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2573104)

[^51]:
     For a discussion of Article 14 and its possible ramifications, see Alexandra Giannopoulou, _The New Copyright Directive: Article 14 or When the Public Domain Enters the New Copyright Directive_, Kluwer Copyright Blog (June 27, 2019),[ http://copyrightblog.kluweriplaw.com/2019/06/27/the-new-copyright-directive-article-14-or-when-the-public-domain-enters-the-new-copyright-directive](http://copyrightblog.kluweriplaw.com/2019/06/27/the-new-copyright-directive-article-14-or-when-the-public-domain-enters-the-new-copyright-directive/)

[^52]:
     _See e.g._, Feist Pub’lns, Inc. v. Rural Tel. Serv. Co., 499 U.S. 340, 350–51 (1991) (“Facts, whether alone or as part of a compilation, are not original and therefore may not be copyrighted. A factual compilation is eligible for copyright if it features an original selection and arrangement of facts, but the copyright is limited to the particular selection and arrangement. In no event may copyright extend to the facts themselves.”) Some jurisdictions, including the EU, do offer protections for information compiled into databases. _See, e.g._, _Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the Legal Protection of Databases_, Official Journal of the European Communities (March 11, 1996),  [https://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:31996L0009:EN:HTML](https://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:31996L0009:EN:HTML)

[^53]:
     _See e.g._, Krista L. Cox, _Metadata and Copyright: Should Institutions License Their Data About Scholarship?_ 1, 2, n.1 (2017), [https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1060&context=scholcom](https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1060&context=scholcom) (noting that while “short factual pieces of data [in metadata] are not copyrightable because they are short phrases and pure facts….longer descriptions may well indeed rise to the level of creative expression and could be protected by copyright, unlike short factual pieces of information”).

[^54]:
     _See e.g._, Thomas Flynn, _Over 100,000 Cultural Heritage 3D Models on Sketchfab_, Sketchfab (October 2, 2019), [https://sketchfab.com/blogs/community/over-100000-cultural-heritage-3d-models-on-sketchfab/](https://sketchfab.com/blogs/community/over-100000-cultural-heritage-3d-models-on-sketchfab/)

[^55]:
     _Cultural Heritage User Survey 2019_, Sketchfab (August 2019), [https://docs.google.com/presentation/d/1avExQtbfl6vDCFyo5VgSyBy638BjdDTAIhw79ClHT5A/edit#slide=id.g5e4c799188_0_573](https://docs.google.com/presentation/d/1avExQtbfl6vDCFyo5VgSyBy638BjdDTAIhw79ClHT5A/edit#slide=id.g5e4c799188_0_573) (demonstrating that a majority of institutions surveyed use no formal quality assurance methods or standards for their 3D production work).

[^56]:

     _What is a DOI and How Do I Use them in Citations?_, University of Illinois Library, [https://library.uic.edu/help/article/1966/what-is-a-doi-and-how-do-i-use-them-in-citations](https://library.uic.edu/help/article/1966/what-is-a-doi-and-how-do-i-use-them-in-citations), last accessed April 16, 2020.

[^57]:
     _See CS3DP Community Standards for 3D Data Preservation_ [https://osf.io/ewt2h/wiki/home, last accessed April 16, 2020](https://osf.io/ewt2h/wiki/home); _see also_
    _IIIF 3D Community Group_, IIIF, [https://iiif.io/community/groups/3d, last accessed April 16, 2020](https://iiif.io/community/groups/3d); _see also_ _3D Content in Europeana_, Europeana 3D Task Force (January 28, 2019), [https://pro.europeana.eu/project/3d-content-in-europeana](https://pro.europeana.eu/project/3d-content-in-europeana)

[^58]:

     The IIIF 3D Community Group maintains a more extended comparison table of these and other online 3D viewers. _IIIF 3D Viewer Functionality Matrix_, IIIF Google Document, [https://docs.google.com/spreadsheets/d/1mZFF1kgEfjqN1MC_Ds0LQyxPvzUUXSHJLksn-uTvtdQ/edit?usp=sharing](https://docs.google.com/spreadsheets/d/1mZFF1kgEfjqN1MC_Ds0LQyxPvzUUXSHJLksn-uTvtdQ/edit?usp=sharing), last accessed April 16, 2020.

[^59]:
     The Creative Commons Public Domain Mark may be appropriate if your institution has positively identified a work to be in the public domain. _See Public Domain Mark 1.0_, Creative Commons, [https://creativecommons.org/publicdomain/mark/1.0/](https://creativecommons.org/publicdomain/mark/1.0/), last accessed April 16, 2020.

[^60]:
     Rightsstatements.org provides 12 standardized rights statements, each with a unique URI and accompanying text, to help with this process.

[^61]:
     Cleveland Museum of Art, _Open Access_, (December 28, 2018), [https://www.clevelandart.org/open-access](https://www.clevelandart.org/open-access)

[^62]:
     Cleveland Museum of Art, _Museum Policies_, (February 14, 2014), [https://www.clevelandart.org/visit/visitor-information/museum-policies](https://www.clevelandart.org/visit/visitor-information/museum-policies)

[^63]:
     Maddie Armitage and Howard Agriesti, _Looking From All Angles: ArtLens Exhibition Embraces Photogrammetry_, Medium (August 8, 2019), [https://medium.com/cma-thinker/looking-from-all-angles-artlens-exhibition-embraces-photogrammetry-d2cb75d61735](https://medium.com/cma-thinker/looking-from-all-angles-artlens-exhibition-embraces-photogrammetry-d2cb75d61735)

[^64]:
     Rijksmuseum, _Sharing Is Caring_, [http://sharecare.nu/](http://sharecare.nu/), last accessed April 16, 2020.

[^65]:
     SMK—National Gallery of Denmark in Copenhagen (Statens Museum for Kunst), _Digital Casts_, [https://www.smk.dk/en/article/digitale-casts/](https://www.smk.dk/en/article/digitale-casts/), last accessed April 16, 2020.

[^66]:
     Merete Sanderhoff, _Scanning SMK, One Sculpture at a Time,_ Medium (August 29, 2019), [https://medium.com/smk-open/scanning-smk-one-sculpture-at-a-time-8e72196219fd](https://medium.com/smk-open/scanning-smk-one-sculpture-at-a-time-8e72196219fd)

[^67]:
     _SMK_—_Statens Museum for Kunst @SMK_—_Statens Museum for Kunst_—_MyMiniFactory_, [https://www.myminifactory.com/users/SMK%20-%20Statens%20Museum%20for%20Kunst](https://www.myminifactory.com/users/SMK%20-%20Statens%20Museum%20for%20Kunst), last accessed December 16, 2019.

[^68]:
     _SMK2 Presents: Digital Casts_—_A 3D Model Collection by SMK_—_National Gallery of Denmark (@smkmuseum)_, Sketchfab, [https://sketchfab.com/smkmuseum/collections/smk2-presents-digital-casts](https://sketchfab.com/smkmuseum/collections/smk2-presents-digital-casts), last accessed April 16, 2020.

[^69]:
     Magnus Kaslov, _Ghost in the Scan—3D Scans of Casts in the SMK’s Collections,_ Medium (March 1, 2017), [https://medium.com/smk-open/ghost-in-the-scan-3d-scans-of-casts-in-the-smks-collections-79560f895369](https://medium.com/smk-open/ghost-in-the-scan-3d-scans-of-casts-in-the-smks-collections-79560f895369)

[^70]:
     Maja Ravn Blichmann, _SMK Open: Art Wants To Be Free_, SMK—National Gallery of Denmark in Copenhagen (Statens Museum for Kunst) (April 30, 2019), [https://www.smk.dk/en/article/art-wants-to-be-free/](https://www.smk.dk/en/article/art-wants-to-be-free/)

[^71]:
     Magnus Kaslov, _Ghost in the Scan—3D Scans of Casts in the SMK’s Collections_, Medium (March 1, 2017), [https://medium.com/smk-open/ghost-in-the-scan-3d-scans-of-casts-in-the-smks-collections-79560f895369](https://medium.com/smk-open/ghost-in-the-scan-3d-scans-of-casts-in-the-smks-collections-79560f895369)

[^72]:
     _Smithsonian 3D_, Smithsonian Digitization Program Office, [https://3d.si.edu/](https://3d.si.edu/), last accessed April 16, 2020.

[^73]:
     Matt Alderton, _Digitization, Documentation, and Democratization: 3D Scanning and the Future of Museums_, Redshift by Autodesk (February 23, 2016), [https://www.autodesk.com/redshift/digitization-future-of-museums/](https://www.autodesk.com/redshift/digitization-future-of-museums/)

[^74]:
     Joseph Stromberg, _Watch: The World’s 3D Experts Converge at the Smithsonian X 3D Conference_, Smithsonian Magazine (November 13, 2013), [https://www.smithsonianmag.com/smithsonian-institution/watch-the-worlds-3d-experts-converge-at-the-smithsonian-x-3d-conference-180947682/](https://www.smithsonianmag.com/smithsonian-institution/watch-the-worlds-3d-experts-converge-at-the-smithsonian-x-3d-conference-180947682/)

[^75]:
     _Smithsonian Voyager_, Smithsonian Digitization Program Office, [https://smithsonian.github.io/dpo-voyager/, last accessed April 16, 2020](https://smithsonian.github.io/dpo-voyager/).

[^76]:
     _Smithsonian 3D Metadata Model_, Smithsonian Digitization Program Office, [https://dpo.si.edu/index.php/blog/smithsonian-3d-metadata-model,](https://dpo.si.edu/index.php/blog/smithsonian-3d-metadata-model) last accessed April 16, 2020.

[^77]:
     _Autodesk Powers 3D Explorer for Smithsonian Institution_, Autodesk (November 13, 2013), [https://investors.autodesk.com/news-releases/news-release-details/autodesk-powers-3d-explorer-smithsonian-institution](https://investors.autodesk.com/news-releases/news-release-details/autodesk-powers-3d-explorer-smithsonian-institution)

[^78]:
     Marc Bretzfelder, _Google Expeditions AR Brings Smithsonian 3D Models into the Home and Classroom via Augmented Reality_, SI Digi Blog (September 14, 2018), [https://dpo.si.edu/index.php/blog/google-expeditions-ar-brings-smithsonian-3d-models-home-and-classroom-augmented-reality](https://dpo.si.edu/index.php/blog/google-expeditions-ar-brings-smithsonian-3d-models-home-and-classroom-augmented-reality)

[^79]:
     _Ewer with Birds, Snakes and Humans, National Museum of Asian Art,_ AWS Sumerian. [https://56bfe6d67d7c4e04a6ab2152540a7e44.us-west-2.sumerian.aws/,](https://56bfe6d67d7c4e04a6ab2152540a7e44.us-west-2.sumerian.aws/) last accessed April 10, 2020.

[^80]:
     _3D Scanning: The 21st-Century Equivalent to a 19th Century Process_, Smithsonian Digitization Program Office, [https://dpo.si.edu/blog/3d-scanning-21st-century-equivalent-19th-century-process,](https://dpo.si.edu/blog/3d-scanning-21st-century-equivalent-19th-century-process) last accessed December 16, 2019.

[^81]:
     _Explore NMAAHC Collections in 3D_, 3d.Si.Edu, [https://3d.si.edu/video/explore-nmaahc-collections-3d](https://3d.si.edu/video/explore-nmaahc-collections-3d), last accessed December 16, 2019.

[^82]:
     _Armstrong Spacesuit_, 3d.Si.Edu, [https://3d.si.edu/armstrong,](https://3d.si.edu/armstrong) last accessed December16, 2019.

[^83]:
     Effie Kapsalis, _21st-Century Diffusion with Smithsonian Open Access_, Smithsonian Open Access  Updates (February 25, 2020), [https://www.si.edu/openaccess/updates/21st-century-diffusion](https://www.si.edu/openaccess/updates/21st-century-diffusion)

[^84]:
    _ Khronos and Smithsonian Collaborate to Diffuse Knowledge for Education, Research, and Creative Use_, Khronos Group Press Release (February 25, 2020), [https://www.khronos.org/news/press/khronos-smithsonian-collaborate-to-diffuse-knowledge-for-education-research-and-creative-use](https://www.khronos.org/news/press/khronos-smithsonian-collaborate-to-diffuse-knowledge-for-education-research-and-creative-use)

[^85]:
     Thomas Flynn, _Sketchfab Launches Public Domain Dedication for 3D Cultural Heritage_,_ _Sketchfab Community Blog (February 25, 2020), [https://sketchfab.com/blogs/community/sketchfab-launches-public-domain-dedication-for-3d-cultural-heritage/](https://sketchfab.com/blogs/community/sketchfab-launches-public-domain-dedication-for-3d-cultural-heritage/)

[^86]:
     _Smithsonian X 3D—Digitizing Collections_, Smithsonian Digitization Program Office (November 13, 2013) 1:11-1:20, [https://youtu.be/_TiHTkK5Wrs?t=71](https://youtu.be/_TiHTkK5Wrs?t=71)

[^87]:
     Further map types are described and demonstrated at _Materials (PBR)_, Sketchfab Help Center, [https://help.sketchfab.com/hc/en-us/articles/204429595-Materials-PBR](https://help.sketchfab.com/hc/en-us/articles/204429595-Materials-PBR), last accessed April 16, 2020.

[^88]:
     This type of image can often be incorporated into visual descriptions designed to provide details to low fixion and blind users.

[^89]:
     Dale Utt III, _How to Create Materials and Textures for Photogrammetry_, Sketchfab Tutorials (November 15, 2019), [https://sketchfab.com/blogs/community/how-to-create-materials-and-textures-for-photogrammetry](https://sketchfab.com/blogs/community/how-to-create-materials-and-textures-for-photogrammetry/)

[^90]:
     Copy Culture: Sharing in the Age of Digital Reproduction 203 (Brendan Cormier ed., 2018), [https://vanda-production-assets.s3.amazonaws.com/2018/06/15/11/42/57/e8582248-8878-486e-8a28-ebb8bf74ace8/Copy%20Culture.pdf](https://vanda-production-assets.s3.amazonaws.com/2018/06/15/11/42/57/e8582248-8878-486e-8a28-ebb8bf74ace8/Copy%20Culture.pdf)

[^91]:
     _Cultural Heritage User Survey 2019_, Sketchfab (August 2019), [https://docs.google.com/presentation/d/1avExQtbfl6vDCFyo5VgSyBy638BjdDTAIhw79ClHT5A/edit#slide=id.g5e4c799188_0_419](https://docs.google.com/presentation/d/1avExQtbfl6vDCFyo5VgSyBy638BjdDTAIhw79ClHT5A/edit#slide=id.g5e4c799188_0_419)

[^92]:
     _Cultural Heritage User Survey 2019_, Sketchfab (August 2019), [https://docs.google.com/presentation/d/1avExQtbfl6vDCFyo5VgSyBy638BjdDTAIhw79ClHT5A/edit#slide=id.g5e4c799188_0_450](https://docs.google.com/presentation/d/1avExQtbfl6vDCFyo5VgSyBy638BjdDTAIhw79ClHT5A/edit#slide=id.g5e4c799188_0_450)

[^93]:
     _See e.g._, Manuel Charr, _How Museums Are Using Minecraft to Gamify Learning Experiences_, MuseumNext (July 17, 2019), [https://www.museumnext.com/article/minecrafting-the-museum](https://www.museumnext.com/article/minecrafting-the-museum)


<!-- Docs to Markdown version 1.0β22 -->
